{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "19ae3d25-5026-4ce0-9ab8-6fe4f623ab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as kb\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "0b22eff1-cd45-43c5-9414-5eecc729af66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# data\n",
    "rawDataFileName = 'AnalyzedData/nnDataSource.csv'\n",
    "pitchControlFileName = 'AnalyzedData/spaceValues.csv'\n",
    "rawData = pd.read_csv(rawDataFileName, header=0, index_col=0)\n",
    "pitchControlData = pd.read_csv(pitchControlFileName, header=0, index_col=0)\n",
    "# display(rawData)\n",
    "\n",
    "rawCols = rawData.columns\n",
    "cols = rawCols[4:]\n",
    "xCols = cols[:-1]\n",
    "yCols = [\"18\"]\n",
    "usableData = rawData[cols]\n",
    "\n",
    "relData = pd.DataFrame()\n",
    "\n",
    "xr = usableData[xCols[0]].to_numpy()\n",
    "yr = usableData[xCols[1]].to_numpy()\n",
    "vr = usableData[xCols[2]].to_numpy()\n",
    "ar = usableData[xCols[3]].to_numpy()\n",
    "orir = usableData[xCols[5]].to_numpy()\n",
    "dirr = usableData[xCols[6]].to_numpy()\n",
    "xt = usableData[xCols[7]].to_numpy()\n",
    "yt = usableData[xCols[8]].to_numpy()\n",
    "vt = usableData[xCols[9]].to_numpy()\n",
    "at = usableData[xCols[10]].to_numpy()\n",
    "orit = usableData[xCols[12]].to_numpy()\n",
    "dirt = usableData[xCols[13]].to_numpy()\n",
    "suc = usableData[yCols[0]].to_numpy()\n",
    "\n",
    "orir = -np.gradient(orir - 90)\n",
    "dirr = -np.gradient(dirr - 90)\n",
    "orit = -np.gradient(orit - 90)\n",
    "dirt = -np.gradient(dirt - 90)\n",
    "\n",
    "relData['x0'] = xr\n",
    "relData['y0'] = yr\n",
    "relData['x1'] = xt - xr\n",
    "relData['y1'] = yt - yr\n",
    "relData['vx0'] = vr * np.cos(dirr)\n",
    "relData['vy0'] = vr * np.sin(dirr)\n",
    "relData['vx1'] = vt * np.cos(dirt)\n",
    "relData['vy1'] = vt * np.sin(dirt)\n",
    "relData['a0'] = ar\n",
    "relData['a1'] = at\n",
    "relData['dir0'] = dirr\n",
    "relData['dir1'] = dirt\n",
    "relData['ori0'] = orir\n",
    "relData['ori1'] = orit\n",
    "relData['pc'] = pitchControlData['pitch control']\n",
    "\n",
    "relNData = preprocessing.normalize(relData)\n",
    "# print(relNData)\n",
    "# normalize by column\n",
    "# dataRange = [(-10, 130, 140), (0, 53.33, 53.33), (0, 14, 14), (0, 7, 7), (0, 1.4, 1.4), (0, 360, 360), (0, 360, 360)]\n",
    "# for j in range(2):\n",
    "#     for i in range(7):\n",
    "#         col = cols[i + j * 7]\n",
    "#         usableData[col] = (usableData[col] - dataRange[i][0]) / dataRange[i][2]\n",
    "# display(usableData)        \n",
    "\n",
    "\n",
    "# Randomly selecting training data\n",
    "\n",
    "# indexes\n",
    "Ntotal = relNData.shape[0]\n",
    "trainingIndex = np.random.choice(Ntotal, int(Ntotal * 0.90), replace=False)\n",
    "validationIndex = np.setdiff1d(np.array(range(Ntotal)), trainingIndex)\n",
    "# data seperation\n",
    "tXSet = relNData[trainingIndex]\n",
    "vXSet = relNData[validationIndex]\n",
    "tYSet = suc[trainingIndex]\n",
    "vYSet = suc[validationIndex]\n",
    "\n",
    "\n",
    "# tXSet = relNData[validationIndex]\n",
    "# vXSet = relNData[validationIndex]\n",
    "# tYSet = relNData[validationIndex]\n",
    "# vYSet = relNData[validationIndex]\n",
    "\n",
    "# display(tSet)\n",
    "# display(vSet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "be3c2627-b161-4ac7-8b06-80acb176da99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "from keras import backend as K\n",
    "initializer = keras.initializers.RandomUniform(minval= -0.2, maxval=0.5)\n",
    "\n",
    "layers = [keras.layers.Dense(8, activation='elu', input_shape=[15],  kernel_initializer=initializer),\n",
    "          keras.layers.Dense(16, activation='elu', kernel_initializer=initializer),\n",
    "          keras.layers.Dense(8, activation='elu', kernel_initializer=initializer),\n",
    "\n",
    "          \n",
    "          \n",
    "          keras.layers.Dense(1, kernel_initializer=initializer)\n",
    "         ]\n",
    "model = keras.Sequential(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "28f38f7e-00ea-44e7-8b87-b13d978941d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "rms = keras.optimizers.RMSprop(0.001)\n",
    "# model.compile(loss='mean_absolute_error',\n",
    "#               optimizer='adam', \n",
    "#               metrics=['accuracy'])\n",
    "model.compile(loss='mean_absolute_error',optimizer=rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "d4d1b816-a355-4519-a67c-9ecfd48f5fd3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smallest loss = 0.2313021719455719\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "es = keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    mode='min', \n",
    "    patience=80, \n",
    "    restore_best_weights=True, \n",
    "    verbose=1)\n",
    "# Add a checkpoint where loss is minimum, and save that model\n",
    "mc = keras.callbacks.ModelCheckpoint('best_model.SB', monitor='loss', \n",
    "                     mode='min',  verbose=0, save_best_only=True)\n",
    "\n",
    "historyData = model.fit(tXSet, \n",
    "                        tYSet,\n",
    "                        epochs=200,\n",
    "                        batch_size = 50,\n",
    "                        callbacks=[es], \n",
    "                        verbose=0)\n",
    "\n",
    "loss_hist = historyData.history['loss']\n",
    "#The above line will return a dictionary, access it's info like this:\n",
    "best_epoch = np.argmin(historyData.history['loss']) + 1\n",
    "\n",
    "# print ('best epoch = ', best_epoch)\n",
    "print('smallest loss =', np.min(loss_hist))\n",
    "minLoss = np.min(loss_hist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "9c0647bd-c349-4c55-b2e3-90c149c07389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201/201 [==============================] - 0s 297us/step - loss: 0.2317\n",
      "23/23 [==============================] - 0s 417us/step - loss: 0.2072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.207227885723114"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analysis\n",
    "model.evaluate(tXSet, tYSet)\n",
    "model.evaluate(vXSet, vYSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d12ae2-f809-4ac3-8845-b9d3ebb24ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
