{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19ae3d25-5026-4ce0-9ab8-6fe4f623ab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN Libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as kb\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7980f4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 28480\n",
      "number of input features: 196\n"
     ]
    }
   ],
   "source": [
    "# Read Raw Data\n",
    "### Data Structure:\n",
    "### Meta-data: GamePlayID, Returner ID, Returner's teammates' ID, Tackling team's ID, \n",
    "### Returner's tracking data, Returner's teammate's tracking data\n",
    "### Tackling team's tracking data\n",
    "### Tracking data includes: x, y, s, a, dis, o, dir, an, d\n",
    "##### x, y, s, a, dis, o, dir remain the same as NFL's definition.\n",
    "##### an is the angle between a player and returner\n",
    "##### d is the euclidean distance between a player and returner\n",
    "\n",
    "tackleFileName = 'AnalyzedData/biggg.csv' # read player data for each frame\n",
    "pitchControlFileName = 'AnalyzedData/spaceValues.csv' # read pitch control score for each frame\n",
    "\n",
    "tackleData = pd.read_csv(tackleFileName, header=0, index_col=0)\n",
    "pitchControlData = pd.read_csv(pitchControlFileName, header=0, index_col=0)\n",
    "\n",
    "# Select usableData (i.e. disregard meta-data such as Game ID, Play ID for training purposes)\n",
    "colNames = tackleData.columns\n",
    "colNamesX = colNames[24:220]\n",
    "colNamesY_outcome = colNames[231:232]\n",
    "colNamesY_identity = colNames[220:231]\n",
    "\n",
    "# X_raw: raw input feature matrix (stored in pandas dataframe)\n",
    "X_raw = tackleData[colNamesX]\n",
    "\n",
    "# Y: output matrix (stored in pandas dataframe)\n",
    "Y_outcome = tackleData[colNamesY_outcome]\n",
    "Y_identity = tackleData[colNamesY_identity]\n",
    "\n",
    "# define nRow, nFeature\n",
    "nRow = X_raw.shape[0]\n",
    "nFeature = X_raw.shape[1]\n",
    "\n",
    "print('number of samples:', nRow)\n",
    "print('number of input features:', nFeature)\n",
    "# display(X_raw)\n",
    "# display(Y_outcome)\n",
    "# display(Y_identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b22eff1-cd45-43c5-9414-5eecc729af66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the scaled input matrix is: (28480, 196)\n"
     ]
    }
   ],
   "source": [
    "# Data Scaling for NN\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler() \n",
    "X_scaled = min_max_scaler.fit_transform(X=X_raw) # linearly scale to range [0, 1]\n",
    "# relNData = preprocessing.normalize(relData) # scale to N(0, 1)\n",
    "print('Shape of the scaled input matrix is:', X_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68c6eb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Explanatory Data Analysis\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# XY = X_scaled\n",
    "# XY['Y'] = Y_outcome.to_numpy()\n",
    "\n",
    "# pca = PCA(n_components=nFeature+1)\n",
    "# pca.fit(XY)\n",
    "\n",
    "# # print('PCA explained variance ratio:', '\\n', pca.explained_variance_ratio_, '\\n')\n",
    "# # print('PCA singular values:', '\\n', pca.singular_values_, '\\n')\n",
    "\n",
    "# corr_matrix = np.corrcoef(XY.T)\n",
    "# print('Shape of covariance matrix is:', corr_matrix.shape)\n",
    "# print('Correlation between all input features and Y:', '\\n', np.round(corr_matrix[nFeature]*100, ), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cc36aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input features : 196\n",
      "Training set has 22784 frames.\n",
      "Training set tackling rate is: [77.11551966] %\n",
      "Validation set has 5696 frames.\n",
      "Validation set tackling rate is: [77.28230337] %\n",
      "(22784, 196)\n"
     ]
    }
   ],
   "source": [
    "# Randomly selecting training data\n",
    "trainPct = 0.8 # select how many data to use in the training set (range = [0, 1])\n",
    "\n",
    "# indexes\n",
    "np.random.seed(seed=1)\n",
    "trainIndex = np.random.choice(nRow, int(nRow * trainPct), replace=False)\n",
    "testIndex = np.setdiff1d(np.array(range(nRow)), trainIndex)\n",
    "\n",
    "# data seperation (all data stored in numpy ndarray)\n",
    "X_train = X_scaled[trainIndex]\n",
    "Y_outcome_train = Y_outcome.to_numpy()[trainIndex]\n",
    "Y_identity_train = Y_identity.to_numpy()[trainIndex]\n",
    "\n",
    "X_test = X_scaled[testIndex]\n",
    "Y_outcome_test = Y_outcome.to_numpy()[testIndex]\n",
    "Y_identity_test = Y_identity.to_numpy()[testIndex]\n",
    "\n",
    "print('Number of input features :', nFeature)\n",
    "print('Training set has', len(Y_outcome_train), 'frames.')\n",
    "print('Training set tackling rate is:', sum(Y_outcome_train)/len(Y_outcome_train)*100, '%')\n",
    "print('Validation set has', len(Y_outcome_test), 'frames.')\n",
    "print('Validation set tackling rate is:', sum(Y_outcome_test)/len(Y_outcome_test)*100, '%')\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be3c2627-b161-4ac7-8b06-80acb176da99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      "712/712 [==============================] - 1s 937us/step - loss: 0.5517 - accuracy: 0.7697 - val_loss: 0.5325 - val_accuracy: 0.7728\n",
      "Epoch 2/4000\n",
      "712/712 [==============================] - 1s 745us/step - loss: 0.5405 - accuracy: 0.7709 - val_loss: 0.5272 - val_accuracy: 0.7728\n",
      "Epoch 3/4000\n",
      "712/712 [==============================] - 1s 712us/step - loss: 0.5349 - accuracy: 0.7711 - val_loss: 0.5248 - val_accuracy: 0.7728\n",
      "Epoch 4/4000\n",
      "712/712 [==============================] - 1s 718us/step - loss: 0.5315 - accuracy: 0.7708 - val_loss: 0.5224 - val_accuracy: 0.7728\n",
      "Epoch 5/4000\n",
      "712/712 [==============================] - 1s 716us/step - loss: 0.5293 - accuracy: 0.7709 - val_loss: 0.5188 - val_accuracy: 0.7728\n",
      "Epoch 6/4000\n",
      "712/712 [==============================] - 1s 706us/step - loss: 0.5269 - accuracy: 0.7709 - val_loss: 0.5166 - val_accuracy: 0.7728\n",
      "Epoch 7/4000\n",
      "712/712 [==============================] - 1s 738us/step - loss: 0.5220 - accuracy: 0.7715 - val_loss: 0.5146 - val_accuracy: 0.7728\n",
      "Epoch 8/4000\n",
      "712/712 [==============================] - 1s 728us/step - loss: 0.5208 - accuracy: 0.7707 - val_loss: 0.5128 - val_accuracy: 0.7728\n",
      "Epoch 9/4000\n",
      "712/712 [==============================] - 1s 706us/step - loss: 0.5194 - accuracy: 0.7712 - val_loss: 0.5109 - val_accuracy: 0.7728\n",
      "Epoch 10/4000\n",
      "712/712 [==============================] - 1s 707us/step - loss: 0.5176 - accuracy: 0.7712 - val_loss: 0.5097 - val_accuracy: 0.7733\n",
      "Epoch 11/4000\n",
      "712/712 [==============================] - 1s 705us/step - loss: 0.5140 - accuracy: 0.7713 - val_loss: 0.5078 - val_accuracy: 0.7732\n",
      "Epoch 12/4000\n",
      "712/712 [==============================] - 1s 720us/step - loss: 0.5126 - accuracy: 0.7716 - val_loss: 0.5064 - val_accuracy: 0.7737\n",
      "Epoch 13/4000\n",
      "712/712 [==============================] - 1s 732us/step - loss: 0.5132 - accuracy: 0.7707 - val_loss: 0.5058 - val_accuracy: 0.7732\n",
      "Epoch 14/4000\n",
      "712/712 [==============================] - 1s 752us/step - loss: 0.5099 - accuracy: 0.7715 - val_loss: 0.5045 - val_accuracy: 0.7730\n",
      "Epoch 15/4000\n",
      "712/712 [==============================] - 1s 732us/step - loss: 0.5090 - accuracy: 0.7714 - val_loss: 0.5041 - val_accuracy: 0.7744\n",
      "Epoch 16/4000\n",
      "712/712 [==============================] - 1s 719us/step - loss: 0.5077 - accuracy: 0.7713 - val_loss: 0.5017 - val_accuracy: 0.7741\n",
      "Epoch 17/4000\n",
      "712/712 [==============================] - 1s 716us/step - loss: 0.5067 - accuracy: 0.7715 - val_loss: 0.5041 - val_accuracy: 0.7725\n",
      "Epoch 18/4000\n",
      "712/712 [==============================] - 1s 723us/step - loss: 0.5043 - accuracy: 0.7725 - val_loss: 0.5031 - val_accuracy: 0.7737\n",
      "Epoch 19/4000\n",
      "712/712 [==============================] - 1s 740us/step - loss: 0.5031 - accuracy: 0.7731 - val_loss: 0.5005 - val_accuracy: 0.7728\n",
      "Epoch 20/4000\n",
      "712/712 [==============================] - 1s 715us/step - loss: 0.5015 - accuracy: 0.7725 - val_loss: 0.4986 - val_accuracy: 0.7742\n",
      "Epoch 21/4000\n",
      "712/712 [==============================] - 1s 737us/step - loss: 0.4999 - accuracy: 0.7729 - val_loss: 0.4973 - val_accuracy: 0.7742\n",
      "Epoch 22/4000\n",
      "712/712 [==============================] - 1s 722us/step - loss: 0.4986 - accuracy: 0.7734 - val_loss: 0.4961 - val_accuracy: 0.7730\n",
      "Epoch 23/4000\n",
      "712/712 [==============================] - 1s 722us/step - loss: 0.4980 - accuracy: 0.7745 - val_loss: 0.4954 - val_accuracy: 0.7749\n",
      "Epoch 24/4000\n",
      "712/712 [==============================] - 1s 734us/step - loss: 0.4966 - accuracy: 0.7744 - val_loss: 0.4945 - val_accuracy: 0.7748\n",
      "Epoch 25/4000\n",
      "712/712 [==============================] - 1s 712us/step - loss: 0.4960 - accuracy: 0.7727 - val_loss: 0.4938 - val_accuracy: 0.7753\n",
      "Epoch 26/4000\n",
      "712/712 [==============================] - 1s 716us/step - loss: 0.4948 - accuracy: 0.7732 - val_loss: 0.4933 - val_accuracy: 0.7762\n",
      "Epoch 27/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.4949 - accuracy: 0.7744 - val_loss: 0.4933 - val_accuracy: 0.7758\n",
      "Epoch 28/4000\n",
      "712/712 [==============================] - 1s 739us/step - loss: 0.4933 - accuracy: 0.7726 - val_loss: 0.4943 - val_accuracy: 0.7755\n",
      "Epoch 29/4000\n",
      "712/712 [==============================] - 1s 726us/step - loss: 0.4910 - accuracy: 0.7744 - val_loss: 0.4915 - val_accuracy: 0.7756\n",
      "Epoch 30/4000\n",
      "712/712 [==============================] - 1s 745us/step - loss: 0.4909 - accuracy: 0.7754 - val_loss: 0.4924 - val_accuracy: 0.7774\n",
      "Epoch 31/4000\n",
      "712/712 [==============================] - 1s 734us/step - loss: 0.4927 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7762\n",
      "Epoch 32/4000\n",
      "712/712 [==============================] - 1s 839us/step - loss: 0.4901 - accuracy: 0.7734 - val_loss: 0.4907 - val_accuracy: 0.7765\n",
      "Epoch 33/4000\n",
      "712/712 [==============================] - 1s 742us/step - loss: 0.4880 - accuracy: 0.7748 - val_loss: 0.4911 - val_accuracy: 0.7783\n",
      "Epoch 34/4000\n",
      "712/712 [==============================] - 1s 731us/step - loss: 0.4886 - accuracy: 0.7756 - val_loss: 0.4898 - val_accuracy: 0.7755\n",
      "Epoch 35/4000\n",
      "712/712 [==============================] - 1s 728us/step - loss: 0.4876 - accuracy: 0.7750 - val_loss: 0.4886 - val_accuracy: 0.7772\n",
      "Epoch 36/4000\n",
      "712/712 [==============================] - 1s 728us/step - loss: 0.4870 - accuracy: 0.7753 - val_loss: 0.4882 - val_accuracy: 0.7776\n",
      "Epoch 37/4000\n",
      "712/712 [==============================] - 1s 730us/step - loss: 0.4862 - accuracy: 0.7755 - val_loss: 0.4878 - val_accuracy: 0.7777\n",
      "Epoch 38/4000\n",
      "712/712 [==============================] - 1s 719us/step - loss: 0.4849 - accuracy: 0.7775 - val_loss: 0.4874 - val_accuracy: 0.7749\n",
      "Epoch 39/4000\n",
      "712/712 [==============================] - 1s 713us/step - loss: 0.4835 - accuracy: 0.7766 - val_loss: 0.4871 - val_accuracy: 0.7805\n",
      "Epoch 40/4000\n",
      "712/712 [==============================] - 1s 722us/step - loss: 0.4834 - accuracy: 0.7764 - val_loss: 0.4868 - val_accuracy: 0.7795\n",
      "Epoch 41/4000\n",
      "712/712 [==============================] - 1s 707us/step - loss: 0.4823 - accuracy: 0.7777 - val_loss: 0.4881 - val_accuracy: 0.7769\n",
      "Epoch 42/4000\n",
      "712/712 [==============================] - 1s 725us/step - loss: 0.4819 - accuracy: 0.7783 - val_loss: 0.4907 - val_accuracy: 0.7790\n",
      "Epoch 43/4000\n",
      "712/712 [==============================] - 1s 739us/step - loss: 0.4811 - accuracy: 0.7777 - val_loss: 0.4858 - val_accuracy: 0.7802\n",
      "Epoch 44/4000\n",
      "712/712 [==============================] - 1s 712us/step - loss: 0.4812 - accuracy: 0.7777 - val_loss: 0.4858 - val_accuracy: 0.7788\n",
      "Epoch 45/4000\n",
      "712/712 [==============================] - 1s 713us/step - loss: 0.4801 - accuracy: 0.7779 - val_loss: 0.4847 - val_accuracy: 0.7784\n",
      "Epoch 46/4000\n",
      "712/712 [==============================] - 1s 714us/step - loss: 0.4798 - accuracy: 0.7791 - val_loss: 0.4848 - val_accuracy: 0.7795\n",
      "Epoch 47/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.4790 - accuracy: 0.7794 - val_loss: 0.4844 - val_accuracy: 0.7798\n",
      "Epoch 48/4000\n",
      "712/712 [==============================] - 1s 717us/step - loss: 0.4773 - accuracy: 0.7798 - val_loss: 0.4847 - val_accuracy: 0.7797\n",
      "Epoch 49/4000\n",
      "712/712 [==============================] - 1s 708us/step - loss: 0.4763 - accuracy: 0.7800 - val_loss: 0.4851 - val_accuracy: 0.7795\n",
      "Epoch 50/4000\n",
      "712/712 [==============================] - 1s 716us/step - loss: 0.4749 - accuracy: 0.7786 - val_loss: 0.4865 - val_accuracy: 0.7781\n",
      "Epoch 51/4000\n",
      "712/712 [==============================] - 1s 726us/step - loss: 0.4746 - accuracy: 0.7812 - val_loss: 0.4842 - val_accuracy: 0.7805\n",
      "Epoch 52/4000\n",
      "712/712 [==============================] - 1s 720us/step - loss: 0.4738 - accuracy: 0.7817 - val_loss: 0.4844 - val_accuracy: 0.7791\n",
      "Epoch 53/4000\n",
      "712/712 [==============================] - 1s 712us/step - loss: 0.4726 - accuracy: 0.7796 - val_loss: 0.4830 - val_accuracy: 0.7807\n",
      "Epoch 54/4000\n",
      "712/712 [==============================] - 1s 713us/step - loss: 0.4733 - accuracy: 0.7817 - val_loss: 0.4844 - val_accuracy: 0.7797\n",
      "Epoch 55/4000\n",
      "712/712 [==============================] - 1s 726us/step - loss: 0.4725 - accuracy: 0.7822 - val_loss: 0.4819 - val_accuracy: 0.7812\n",
      "Epoch 56/4000\n",
      "712/712 [==============================] - 1s 721us/step - loss: 0.4710 - accuracy: 0.7811 - val_loss: 0.4829 - val_accuracy: 0.7790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/4000\n",
      "712/712 [==============================] - 1s 721us/step - loss: 0.4707 - accuracy: 0.7827 - val_loss: 0.4815 - val_accuracy: 0.7804\n",
      "Epoch 58/4000\n",
      "712/712 [==============================] - 1s 721us/step - loss: 0.4697 - accuracy: 0.7828 - val_loss: 0.4825 - val_accuracy: 0.7823\n",
      "Epoch 59/4000\n",
      "712/712 [==============================] - 1s 726us/step - loss: 0.4689 - accuracy: 0.7820 - val_loss: 0.4816 - val_accuracy: 0.7809\n",
      "Epoch 60/4000\n",
      "712/712 [==============================] - 1s 713us/step - loss: 0.4683 - accuracy: 0.7831 - val_loss: 0.4818 - val_accuracy: 0.7804\n",
      "Epoch 61/4000\n",
      "712/712 [==============================] - 1s 704us/step - loss: 0.4654 - accuracy: 0.7838 - val_loss: 0.4823 - val_accuracy: 0.7809\n",
      "Epoch 62/4000\n",
      "712/712 [==============================] - 1s 730us/step - loss: 0.4676 - accuracy: 0.7835 - val_loss: 0.4809 - val_accuracy: 0.7804\n",
      "Epoch 63/4000\n",
      "712/712 [==============================] - 1s 805us/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.4826 - val_accuracy: 0.7783\n",
      "Epoch 64/4000\n",
      "712/712 [==============================] - 1s 723us/step - loss: 0.4640 - accuracy: 0.7852 - val_loss: 0.4830 - val_accuracy: 0.7776\n",
      "Epoch 65/4000\n",
      "712/712 [==============================] - 1s 720us/step - loss: 0.4654 - accuracy: 0.7839 - val_loss: 0.4834 - val_accuracy: 0.7758\n",
      "Epoch 66/4000\n",
      "712/712 [==============================] - 1s 707us/step - loss: 0.4635 - accuracy: 0.7834 - val_loss: 0.4800 - val_accuracy: 0.7816\n",
      "Epoch 67/4000\n",
      "712/712 [==============================] - 1s 709us/step - loss: 0.4643 - accuracy: 0.7821 - val_loss: 0.4795 - val_accuracy: 0.7823\n",
      "Epoch 68/4000\n",
      "712/712 [==============================] - 1s 706us/step - loss: 0.4622 - accuracy: 0.7889 - val_loss: 0.4793 - val_accuracy: 0.7802\n",
      "Epoch 69/4000\n",
      "712/712 [==============================] - 1s 709us/step - loss: 0.4627 - accuracy: 0.7867 - val_loss: 0.4801 - val_accuracy: 0.7816\n",
      "Epoch 70/4000\n",
      "712/712 [==============================] - 1s 706us/step - loss: 0.4615 - accuracy: 0.7870 - val_loss: 0.4799 - val_accuracy: 0.7823\n",
      "Epoch 71/4000\n",
      "712/712 [==============================] - 1s 730us/step - loss: 0.4592 - accuracy: 0.7866 - val_loss: 0.4796 - val_accuracy: 0.7823\n",
      "Epoch 72/4000\n",
      "712/712 [==============================] - 1s 742us/step - loss: 0.4575 - accuracy: 0.7854 - val_loss: 0.4796 - val_accuracy: 0.7839\n",
      "Epoch 73/4000\n",
      "712/712 [==============================] - 1s 713us/step - loss: 0.4570 - accuracy: 0.7885 - val_loss: 0.4792 - val_accuracy: 0.7827\n",
      "Epoch 74/4000\n",
      "712/712 [==============================] - 1s 721us/step - loss: 0.4576 - accuracy: 0.7880 - val_loss: 0.4785 - val_accuracy: 0.7816\n",
      "Epoch 75/4000\n",
      "712/712 [==============================] - 1s 721us/step - loss: 0.4565 - accuracy: 0.7887 - val_loss: 0.4776 - val_accuracy: 0.7805\n",
      "Epoch 76/4000\n",
      "712/712 [==============================] - 1s 711us/step - loss: 0.4571 - accuracy: 0.7871 - val_loss: 0.4808 - val_accuracy: 0.7828\n",
      "Epoch 77/4000\n",
      "712/712 [==============================] - 1s 716us/step - loss: 0.4559 - accuracy: 0.7867 - val_loss: 0.4789 - val_accuracy: 0.7802\n",
      "Epoch 78/4000\n",
      "712/712 [==============================] - 1s 727us/step - loss: 0.4549 - accuracy: 0.7893 - val_loss: 0.4780 - val_accuracy: 0.7795\n",
      "Epoch 79/4000\n",
      "712/712 [==============================] - 1s 723us/step - loss: 0.4511 - accuracy: 0.7896 - val_loss: 0.4802 - val_accuracy: 0.7832\n",
      "Epoch 80/4000\n",
      "712/712 [==============================] - 1s 713us/step - loss: 0.4497 - accuracy: 0.7906 - val_loss: 0.4771 - val_accuracy: 0.7805\n",
      "Epoch 81/4000\n",
      "712/712 [==============================] - 1s 729us/step - loss: 0.4510 - accuracy: 0.7917 - val_loss: 0.4829 - val_accuracy: 0.7811\n",
      "Epoch 82/4000\n",
      "712/712 [==============================] - 1s 711us/step - loss: 0.4489 - accuracy: 0.7933 - val_loss: 0.4770 - val_accuracy: 0.7818\n",
      "Epoch 83/4000\n",
      "712/712 [==============================] - 1s 705us/step - loss: 0.4491 - accuracy: 0.7916 - val_loss: 0.4766 - val_accuracy: 0.7790\n",
      "Epoch 84/4000\n",
      "712/712 [==============================] - 1s 711us/step - loss: 0.4484 - accuracy: 0.7920 - val_loss: 0.4789 - val_accuracy: 0.7820\n",
      "Epoch 85/4000\n",
      "712/712 [==============================] - 1s 712us/step - loss: 0.4470 - accuracy: 0.7939 - val_loss: 0.4755 - val_accuracy: 0.7791\n",
      "Epoch 86/4000\n",
      "712/712 [==============================] - 1s 705us/step - loss: 0.4474 - accuracy: 0.7928 - val_loss: 0.4765 - val_accuracy: 0.7835\n",
      "Epoch 87/4000\n",
      "712/712 [==============================] - 1s 727us/step - loss: 0.4449 - accuracy: 0.7946 - val_loss: 0.4769 - val_accuracy: 0.7842\n",
      "Epoch 88/4000\n",
      "712/712 [==============================] - 1s 727us/step - loss: 0.4447 - accuracy: 0.7941 - val_loss: 0.4764 - val_accuracy: 0.7825\n",
      "Epoch 89/4000\n",
      "712/712 [==============================] - 1s 719us/step - loss: 0.4442 - accuracy: 0.7960 - val_loss: 0.4749 - val_accuracy: 0.7827\n",
      "Epoch 90/4000\n",
      "712/712 [==============================] - 1s 719us/step - loss: 0.4432 - accuracy: 0.7967 - val_loss: 0.4780 - val_accuracy: 0.7820\n",
      "Epoch 91/4000\n",
      "712/712 [==============================] - 1s 709us/step - loss: 0.4415 - accuracy: 0.7964 - val_loss: 0.4802 - val_accuracy: 0.7839\n",
      "Epoch 92/4000\n",
      "712/712 [==============================] - 1s 716us/step - loss: 0.4378 - accuracy: 0.7999 - val_loss: 0.4768 - val_accuracy: 0.7844\n",
      "Epoch 93/4000\n",
      "712/712 [==============================] - 1s 724us/step - loss: 0.4392 - accuracy: 0.7970 - val_loss: 0.4818 - val_accuracy: 0.7791\n",
      "Epoch 94/4000\n",
      "712/712 [==============================] - 1s 786us/step - loss: 0.4374 - accuracy: 0.7977 - val_loss: 0.4775 - val_accuracy: 0.7844\n",
      "Epoch 95/4000\n",
      "712/712 [==============================] - 1s 719us/step - loss: 0.4392 - accuracy: 0.7980 - val_loss: 0.4763 - val_accuracy: 0.7837\n",
      "Epoch 96/4000\n",
      "712/712 [==============================] - 1s 716us/step - loss: 0.4365 - accuracy: 0.7983 - val_loss: 0.4747 - val_accuracy: 0.7835\n",
      "Epoch 97/4000\n",
      "712/712 [==============================] - 1s 707us/step - loss: 0.4360 - accuracy: 0.8006 - val_loss: 0.4773 - val_accuracy: 0.7841\n",
      "Epoch 98/4000\n",
      "712/712 [==============================] - 1s 744us/step - loss: 0.4340 - accuracy: 0.8018 - val_loss: 0.4744 - val_accuracy: 0.7853\n",
      "Epoch 99/4000\n",
      "712/712 [==============================] - 1s 709us/step - loss: 0.4336 - accuracy: 0.8000 - val_loss: 0.4738 - val_accuracy: 0.7855\n",
      "Epoch 100/4000\n",
      "712/712 [==============================] - 1s 708us/step - loss: 0.4320 - accuracy: 0.7998 - val_loss: 0.4732 - val_accuracy: 0.7844\n",
      "Epoch 101/4000\n",
      "712/712 [==============================] - 1s 706us/step - loss: 0.4311 - accuracy: 0.8038 - val_loss: 0.4733 - val_accuracy: 0.7860\n",
      "Epoch 102/4000\n",
      "712/712 [==============================] - 1s 712us/step - loss: 0.4291 - accuracy: 0.8049 - val_loss: 0.4729 - val_accuracy: 0.7876\n",
      "Epoch 103/4000\n",
      "712/712 [==============================] - 1s 713us/step - loss: 0.4296 - accuracy: 0.8025 - val_loss: 0.4736 - val_accuracy: 0.7827\n",
      "Epoch 104/4000\n",
      "712/712 [==============================] - 1s 711us/step - loss: 0.4276 - accuracy: 0.8059 - val_loss: 0.4750 - val_accuracy: 0.7820\n",
      "Epoch 105/4000\n",
      "712/712 [==============================] - 1s 711us/step - loss: 0.4251 - accuracy: 0.8054 - val_loss: 0.4750 - val_accuracy: 0.7883\n",
      "Epoch 106/4000\n",
      "712/712 [==============================] - 1s 706us/step - loss: 0.4249 - accuracy: 0.8053 - val_loss: 0.4758 - val_accuracy: 0.7837\n",
      "Epoch 107/4000\n",
      "712/712 [==============================] - 1s 704us/step - loss: 0.4250 - accuracy: 0.8038 - val_loss: 0.4737 - val_accuracy: 0.7860\n",
      "Epoch 108/4000\n",
      "712/712 [==============================] - 1s 711us/step - loss: 0.4237 - accuracy: 0.8080 - val_loss: 0.4738 - val_accuracy: 0.7823\n",
      "Epoch 109/4000\n",
      "712/712 [==============================] - 1s 705us/step - loss: 0.4225 - accuracy: 0.8042 - val_loss: 0.4775 - val_accuracy: 0.7860\n",
      "Epoch 110/4000\n",
      "712/712 [==============================] - 1s 718us/step - loss: 0.4209 - accuracy: 0.8090 - val_loss: 0.4747 - val_accuracy: 0.7876\n",
      "Epoch 111/4000\n",
      "712/712 [==============================] - 1s 708us/step - loss: 0.4193 - accuracy: 0.8079 - val_loss: 0.4723 - val_accuracy: 0.7863\n",
      "Epoch 112/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 1s 710us/step - loss: 0.4170 - accuracy: 0.8111 - val_loss: 0.4750 - val_accuracy: 0.7874\n",
      "Epoch 113/4000\n",
      "712/712 [==============================] - 1s 703us/step - loss: 0.4163 - accuracy: 0.8099 - val_loss: 0.4704 - val_accuracy: 0.7872\n",
      "Epoch 114/4000\n",
      "712/712 [==============================] - 1s 711us/step - loss: 0.4147 - accuracy: 0.8102 - val_loss: 0.4739 - val_accuracy: 0.7849\n",
      "Epoch 115/4000\n",
      "712/712 [==============================] - 1s 710us/step - loss: 0.4154 - accuracy: 0.8088 - val_loss: 0.4746 - val_accuracy: 0.7916\n",
      "Epoch 116/4000\n",
      "712/712 [==============================] - 1s 709us/step - loss: 0.4150 - accuracy: 0.8129 - val_loss: 0.4712 - val_accuracy: 0.7872\n",
      "Epoch 117/4000\n",
      "712/712 [==============================] - 1s 706us/step - loss: 0.4131 - accuracy: 0.8139 - val_loss: 0.4713 - val_accuracy: 0.7863\n",
      "Epoch 118/4000\n",
      "712/712 [==============================] - 1s 720us/step - loss: 0.4097 - accuracy: 0.8127 - val_loss: 0.4730 - val_accuracy: 0.7897\n",
      "Epoch 119/4000\n",
      "712/712 [==============================] - 1s 706us/step - loss: 0.4096 - accuracy: 0.8121 - val_loss: 0.4752 - val_accuracy: 0.7904\n",
      "Epoch 120/4000\n",
      "712/712 [==============================] - 1s 705us/step - loss: 0.4101 - accuracy: 0.8153 - val_loss: 0.4718 - val_accuracy: 0.7927\n",
      "Epoch 121/4000\n",
      "712/712 [==============================] - 1s 706us/step - loss: 0.4046 - accuracy: 0.8164 - val_loss: 0.4786 - val_accuracy: 0.7899\n",
      "Epoch 122/4000\n",
      "712/712 [==============================] - 1s 713us/step - loss: 0.4073 - accuracy: 0.8159 - val_loss: 0.4738 - val_accuracy: 0.7904\n",
      "Epoch 123/4000\n",
      "712/712 [==============================] - 1s 706us/step - loss: 0.4051 - accuracy: 0.8166 - val_loss: 0.4701 - val_accuracy: 0.7934\n",
      "Epoch 124/4000\n",
      "712/712 [==============================] - 1s 707us/step - loss: 0.4044 - accuracy: 0.8172 - val_loss: 0.4732 - val_accuracy: 0.7902\n",
      "Epoch 125/4000\n",
      "712/712 [==============================] - 1s 775us/step - loss: 0.4025 - accuracy: 0.8190 - val_loss: 0.4684 - val_accuracy: 0.7914\n",
      "Epoch 126/4000\n",
      "712/712 [==============================] - 1s 748us/step - loss: 0.3992 - accuracy: 0.8191 - val_loss: 0.4743 - val_accuracy: 0.7860\n",
      "Epoch 127/4000\n",
      "712/712 [==============================] - 1s 707us/step - loss: 0.3975 - accuracy: 0.8197 - val_loss: 0.4743 - val_accuracy: 0.7883\n",
      "Epoch 128/4000\n",
      "712/712 [==============================] - 1s 709us/step - loss: 0.3950 - accuracy: 0.8207 - val_loss: 0.4752 - val_accuracy: 0.7904\n",
      "Epoch 129/4000\n",
      "712/712 [==============================] - 1s 712us/step - loss: 0.3965 - accuracy: 0.8221 - val_loss: 0.4693 - val_accuracy: 0.7913\n",
      "Epoch 130/4000\n",
      "712/712 [==============================] - 1s 729us/step - loss: 0.3952 - accuracy: 0.8187 - val_loss: 0.4739 - val_accuracy: 0.7939\n",
      "Epoch 131/4000\n",
      "712/712 [==============================] - 1s 710us/step - loss: 0.3928 - accuracy: 0.8245 - val_loss: 0.4706 - val_accuracy: 0.7837\n",
      "Epoch 132/4000\n",
      "712/712 [==============================] - 1s 707us/step - loss: 0.3938 - accuracy: 0.8237 - val_loss: 0.4714 - val_accuracy: 0.7895\n",
      "Epoch 133/4000\n",
      "712/712 [==============================] - 1s 714us/step - loss: 0.3919 - accuracy: 0.8211 - val_loss: 0.4712 - val_accuracy: 0.7920\n",
      "Epoch 134/4000\n",
      "712/712 [==============================] - 1s 710us/step - loss: 0.3898 - accuracy: 0.8256 - val_loss: 0.4693 - val_accuracy: 0.7899\n",
      "Epoch 135/4000\n",
      "712/712 [==============================] - 1s 710us/step - loss: 0.3887 - accuracy: 0.8252 - val_loss: 0.4706 - val_accuracy: 0.7920\n",
      "Epoch 136/4000\n",
      "712/712 [==============================] - 1s 708us/step - loss: 0.3879 - accuracy: 0.8276 - val_loss: 0.4715 - val_accuracy: 0.7897\n",
      "Epoch 137/4000\n",
      "712/712 [==============================] - 1s 721us/step - loss: 0.3865 - accuracy: 0.8288 - val_loss: 0.4699 - val_accuracy: 0.7918\n",
      "Epoch 138/4000\n",
      "712/712 [==============================] - 1s 709us/step - loss: 0.3847 - accuracy: 0.8296 - val_loss: 0.4696 - val_accuracy: 0.7902\n",
      "Epoch 139/4000\n",
      "712/712 [==============================] - 1s 709us/step - loss: 0.3816 - accuracy: 0.8294 - val_loss: 0.4763 - val_accuracy: 0.7925\n",
      "Epoch 140/4000\n",
      "712/712 [==============================] - 1s 706us/step - loss: 0.3801 - accuracy: 0.8310 - val_loss: 0.4685 - val_accuracy: 0.7881\n",
      "Epoch 141/4000\n",
      "712/712 [==============================] - 1s 712us/step - loss: 0.3809 - accuracy: 0.8291 - val_loss: 0.4693 - val_accuracy: 0.7884\n",
      "Epoch 142/4000\n",
      "712/712 [==============================] - 1s 707us/step - loss: 0.3790 - accuracy: 0.8323 - val_loss: 0.4692 - val_accuracy: 0.7937\n",
      "Epoch 143/4000\n",
      "712/712 [==============================] - 1s 704us/step - loss: 0.3774 - accuracy: 0.8309 - val_loss: 0.4724 - val_accuracy: 0.7897\n",
      "Epoch 144/4000\n",
      "712/712 [==============================] - 1s 709us/step - loss: 0.3752 - accuracy: 0.8328 - val_loss: 0.4722 - val_accuracy: 0.7886\n",
      "Epoch 145/4000\n",
      "712/712 [==============================] - 1s 712us/step - loss: 0.3726 - accuracy: 0.8336 - val_loss: 0.4748 - val_accuracy: 0.7865\n",
      "Epoch 146/4000\n",
      "712/712 [==============================] - 1s 706us/step - loss: 0.3679 - accuracy: 0.8371 - val_loss: 0.4822 - val_accuracy: 0.7906\n",
      "Epoch 147/4000\n",
      "712/712 [==============================] - 1s 707us/step - loss: 0.3703 - accuracy: 0.8364 - val_loss: 0.4708 - val_accuracy: 0.7897\n",
      "Epoch 148/4000\n",
      "712/712 [==============================] - 1s 707us/step - loss: 0.3643 - accuracy: 0.8386 - val_loss: 0.4891 - val_accuracy: 0.7921\n",
      "Epoch 149/4000\n",
      "712/712 [==============================] - 1s 715us/step - loss: 0.3686 - accuracy: 0.8363 - val_loss: 0.4737 - val_accuracy: 0.7909\n",
      "Epoch 150/4000\n",
      "712/712 [==============================] - 1s 720us/step - loss: 0.3652 - accuracy: 0.8368 - val_loss: 0.4795 - val_accuracy: 0.7916\n",
      "Epoch 151/4000\n",
      "712/712 [==============================] - 1s 713us/step - loss: 0.3641 - accuracy: 0.8383 - val_loss: 0.4780 - val_accuracy: 0.7930\n",
      "Epoch 152/4000\n",
      "712/712 [==============================] - 1s 709us/step - loss: 0.3632 - accuracy: 0.8397 - val_loss: 0.4683 - val_accuracy: 0.7928\n",
      "Epoch 153/4000\n",
      "712/712 [==============================] - 1s 713us/step - loss: 0.3613 - accuracy: 0.8389 - val_loss: 0.4827 - val_accuracy: 0.7911\n",
      "Epoch 154/4000\n",
      "712/712 [==============================] - 1s 706us/step - loss: 0.3587 - accuracy: 0.8404 - val_loss: 0.4712 - val_accuracy: 0.7886\n",
      "Epoch 155/4000\n",
      "712/712 [==============================] - 1s 714us/step - loss: 0.3560 - accuracy: 0.8442 - val_loss: 0.4771 - val_accuracy: 0.7909\n",
      "Epoch 156/4000\n",
      "712/712 [==============================] - 1s 748us/step - loss: 0.3544 - accuracy: 0.8432 - val_loss: 0.4753 - val_accuracy: 0.7918\n",
      "Epoch 157/4000\n",
      "712/712 [==============================] - 1s 796us/step - loss: 0.3553 - accuracy: 0.8419 - val_loss: 0.4757 - val_accuracy: 0.7955\n",
      "Epoch 158/4000\n",
      "712/712 [==============================] - 1s 714us/step - loss: 0.3532 - accuracy: 0.8444 - val_loss: 0.4720 - val_accuracy: 0.7897\n",
      "Epoch 159/4000\n",
      "712/712 [==============================] - 1s 715us/step - loss: 0.3485 - accuracy: 0.8491 - val_loss: 0.4753 - val_accuracy: 0.7869\n",
      "Epoch 160/4000\n",
      "712/712 [==============================] - 1s 708us/step - loss: 0.3496 - accuracy: 0.8472 - val_loss: 0.4790 - val_accuracy: 0.7923\n",
      "Epoch 161/4000\n",
      "712/712 [==============================] - 1s 712us/step - loss: 0.3468 - accuracy: 0.8485 - val_loss: 0.4855 - val_accuracy: 0.7942\n",
      "Epoch 162/4000\n",
      "712/712 [==============================] - 1s 711us/step - loss: 0.3443 - accuracy: 0.8472 - val_loss: 0.4819 - val_accuracy: 0.7958\n",
      "Epoch 163/4000\n",
      "712/712 [==============================] - 1s 710us/step - loss: 0.3437 - accuracy: 0.8514 - val_loss: 0.4934 - val_accuracy: 0.7928\n",
      "Epoch 164/4000\n",
      "712/712 [==============================] - 1s 737us/step - loss: 0.3441 - accuracy: 0.8508 - val_loss: 0.4763 - val_accuracy: 0.7876\n",
      "Epoch 165/4000\n",
      "712/712 [==============================] - 1s 724us/step - loss: 0.3386 - accuracy: 0.8525 - val_loss: 0.4786 - val_accuracy: 0.7902\n",
      "Epoch 166/4000\n",
      "712/712 [==============================] - 1s 716us/step - loss: 0.3387 - accuracy: 0.8529 - val_loss: 0.4826 - val_accuracy: 0.7920\n",
      "Epoch 167/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 1s 723us/step - loss: 0.3378 - accuracy: 0.8513 - val_loss: 0.4739 - val_accuracy: 0.7883\n",
      "Epoch 168/4000\n",
      "712/712 [==============================] - 1s 722us/step - loss: 0.3376 - accuracy: 0.8516 - val_loss: 0.4739 - val_accuracy: 0.7932\n",
      "Epoch 169/4000\n",
      "712/712 [==============================] - 1s 734us/step - loss: 0.3333 - accuracy: 0.8544 - val_loss: 0.4895 - val_accuracy: 0.7741\n",
      "Epoch 170/4000\n",
      "712/712 [==============================] - 1s 716us/step - loss: 0.3345 - accuracy: 0.8531 - val_loss: 0.4832 - val_accuracy: 0.7914\n",
      "Epoch 171/4000\n",
      "712/712 [==============================] - 1s 751us/step - loss: 0.3317 - accuracy: 0.8537 - val_loss: 0.4802 - val_accuracy: 0.7888\n",
      "Epoch 172/4000\n",
      "712/712 [==============================] - 1s 714us/step - loss: 0.3283 - accuracy: 0.8573 - val_loss: 0.4768 - val_accuracy: 0.7930\n",
      "Epoch 173/4000\n",
      "712/712 [==============================] - 1s 707us/step - loss: 0.3286 - accuracy: 0.8570 - val_loss: 0.5093 - val_accuracy: 0.7556\n",
      "Epoch 174/4000\n",
      "712/712 [==============================] - 1s 740us/step - loss: 0.3270 - accuracy: 0.8568 - val_loss: 0.4792 - val_accuracy: 0.7948\n",
      "Epoch 175/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.3255 - accuracy: 0.8581 - val_loss: 0.4848 - val_accuracy: 0.7916\n",
      "Epoch 176/4000\n",
      "712/712 [==============================] - 1s 736us/step - loss: 0.3227 - accuracy: 0.8598 - val_loss: 0.4785 - val_accuracy: 0.7923\n",
      "Epoch 177/4000\n",
      "712/712 [==============================] - 1s 724us/step - loss: 0.3205 - accuracy: 0.8628 - val_loss: 0.4833 - val_accuracy: 0.7900\n",
      "Epoch 178/4000\n",
      "712/712 [==============================] - 1s 709us/step - loss: 0.3185 - accuracy: 0.8626 - val_loss: 0.4872 - val_accuracy: 0.7932\n",
      "Epoch 179/4000\n",
      "712/712 [==============================] - 1s 707us/step - loss: 0.3154 - accuracy: 0.8635 - val_loss: 0.4823 - val_accuracy: 0.7902\n",
      "Epoch 180/4000\n",
      "712/712 [==============================] - 1s 711us/step - loss: 0.3175 - accuracy: 0.8600 - val_loss: 0.4801 - val_accuracy: 0.7897\n",
      "Epoch 181/4000\n",
      "712/712 [==============================] - 1s 706us/step - loss: 0.3163 - accuracy: 0.8633 - val_loss: 0.4945 - val_accuracy: 0.7769\n",
      "Epoch 182/4000\n",
      "712/712 [==============================] - 1s 709us/step - loss: 0.3146 - accuracy: 0.8619 - val_loss: 0.4791 - val_accuracy: 0.7893\n",
      "Epoch 183/4000\n",
      "712/712 [==============================] - 1s 717us/step - loss: 0.3106 - accuracy: 0.8646 - val_loss: 0.4795 - val_accuracy: 0.7846\n",
      "Epoch 184/4000\n",
      "712/712 [==============================] - 1s 708us/step - loss: 0.3090 - accuracy: 0.8693 - val_loss: 0.4831 - val_accuracy: 0.7895\n",
      "Epoch 185/4000\n",
      "712/712 [==============================] - 1s 704us/step - loss: 0.3051 - accuracy: 0.8692 - val_loss: 0.4964 - val_accuracy: 0.7969\n",
      "Epoch 186/4000\n",
      "712/712 [==============================] - 1s 707us/step - loss: 0.3040 - accuracy: 0.8689 - val_loss: 0.4856 - val_accuracy: 0.7877\n",
      "Epoch 187/4000\n",
      "712/712 [==============================] - 1s 747us/step - loss: 0.3038 - accuracy: 0.8693 - val_loss: 0.4871 - val_accuracy: 0.7946\n",
      "Epoch 188/4000\n",
      "712/712 [==============================] - 1s 776us/step - loss: 0.3027 - accuracy: 0.8702 - val_loss: 0.4897 - val_accuracy: 0.7893\n",
      "Epoch 189/4000\n",
      "712/712 [==============================] - 1s 722us/step - loss: 0.3019 - accuracy: 0.8723 - val_loss: 0.4836 - val_accuracy: 0.7911\n",
      "Epoch 190/4000\n",
      "712/712 [==============================] - 1s 712us/step - loss: 0.2993 - accuracy: 0.8719 - val_loss: 0.4945 - val_accuracy: 0.7928\n",
      "Epoch 191/4000\n",
      "712/712 [==============================] - 1s 708us/step - loss: 0.2975 - accuracy: 0.8716 - val_loss: 0.5144 - val_accuracy: 0.7963\n",
      "Epoch 192/4000\n",
      "712/712 [==============================] - 1s 714us/step - loss: 0.2973 - accuracy: 0.8714 - val_loss: 0.4879 - val_accuracy: 0.7986\n",
      "Epoch 193/4000\n",
      "712/712 [==============================] - 1s 710us/step - loss: 0.2969 - accuracy: 0.8711 - val_loss: 0.4877 - val_accuracy: 0.7865\n",
      "Epoch 194/4000\n",
      "712/712 [==============================] - 1s 756us/step - loss: 0.2916 - accuracy: 0.8740 - val_loss: 0.4951 - val_accuracy: 0.7913\n",
      "Epoch 195/4000\n",
      "712/712 [==============================] - 1s 723us/step - loss: 0.2890 - accuracy: 0.8748 - val_loss: 0.4932 - val_accuracy: 0.7872\n",
      "Epoch 196/4000\n",
      "712/712 [==============================] - 1s 707us/step - loss: 0.2930 - accuracy: 0.8745 - val_loss: 0.5000 - val_accuracy: 0.7985\n",
      "Epoch 197/4000\n",
      "712/712 [==============================] - 1s 707us/step - loss: 0.2885 - accuracy: 0.8767 - val_loss: 0.4893 - val_accuracy: 0.7856\n",
      "Epoch 198/4000\n",
      "712/712 [==============================] - 1s 711us/step - loss: 0.2866 - accuracy: 0.8760 - val_loss: 0.4894 - val_accuracy: 0.7914\n",
      "Epoch 199/4000\n",
      "712/712 [==============================] - 1s 705us/step - loss: 0.2865 - accuracy: 0.8754 - val_loss: 0.4981 - val_accuracy: 0.7969\n",
      "Epoch 200/4000\n",
      "712/712 [==============================] - 1s 714us/step - loss: 0.2831 - accuracy: 0.8804 - val_loss: 0.5001 - val_accuracy: 0.7798\n",
      "Epoch 201/4000\n",
      "712/712 [==============================] - 1s 707us/step - loss: 0.2797 - accuracy: 0.8794 - val_loss: 0.4991 - val_accuracy: 0.7942\n",
      "Epoch 202/4000\n",
      "712/712 [==============================] - 1s 712us/step - loss: 0.2838 - accuracy: 0.8773 - val_loss: 0.4939 - val_accuracy: 0.7951\n",
      "Epoch 203/4000\n",
      "712/712 [==============================] - 0s 700us/step - loss: 0.2806 - accuracy: 0.8809 - val_loss: 0.4957 - val_accuracy: 0.7944\n",
      "Epoch 204/4000\n",
      "712/712 [==============================] - 1s 715us/step - loss: 0.2786 - accuracy: 0.8812 - val_loss: 0.4988 - val_accuracy: 0.7974\n",
      "Epoch 205/4000\n",
      "712/712 [==============================] - 1s 723us/step - loss: 0.2772 - accuracy: 0.8824 - val_loss: 0.5219 - val_accuracy: 0.7951\n",
      "Epoch 206/4000\n",
      "712/712 [==============================] - 1s 722us/step - loss: 0.2753 - accuracy: 0.8848 - val_loss: 0.5038 - val_accuracy: 0.7948\n",
      "Epoch 207/4000\n",
      "712/712 [==============================] - 1s 710us/step - loss: 0.2748 - accuracy: 0.8814 - val_loss: 0.4994 - val_accuracy: 0.7865\n",
      "Epoch 208/4000\n",
      "712/712 [==============================] - 1s 740us/step - loss: 0.2714 - accuracy: 0.8845 - val_loss: 0.4985 - val_accuracy: 0.7963\n",
      "Epoch 209/4000\n",
      "712/712 [==============================] - 1s 725us/step - loss: 0.2720 - accuracy: 0.8839 - val_loss: 0.4929 - val_accuracy: 0.7909\n",
      "Epoch 210/4000\n",
      "712/712 [==============================] - 1s 714us/step - loss: 0.2688 - accuracy: 0.8854 - val_loss: 0.5017 - val_accuracy: 0.7842\n",
      "Epoch 211/4000\n",
      "712/712 [==============================] - 1s 705us/step - loss: 0.2691 - accuracy: 0.8865 - val_loss: 0.5035 - val_accuracy: 0.7942\n",
      "Epoch 212/4000\n",
      "712/712 [==============================] - 1s 710us/step - loss: 0.2644 - accuracy: 0.8886 - val_loss: 0.5034 - val_accuracy: 0.7886\n",
      "Epoch 213/4000\n",
      "712/712 [==============================] - 1s 712us/step - loss: 0.2647 - accuracy: 0.8886 - val_loss: 0.4995 - val_accuracy: 0.7888\n",
      "Epoch 214/4000\n",
      "712/712 [==============================] - 1s 709us/step - loss: 0.2608 - accuracy: 0.8900 - val_loss: 0.5097 - val_accuracy: 0.7990\n",
      "Epoch 215/4000\n",
      "712/712 [==============================] - 1s 722us/step - loss: 0.2609 - accuracy: 0.8878 - val_loss: 0.5068 - val_accuracy: 0.7962\n",
      "Epoch 216/4000\n",
      "712/712 [==============================] - 1s 724us/step - loss: 0.2608 - accuracy: 0.8921 - val_loss: 0.5013 - val_accuracy: 0.7955\n",
      "Epoch 217/4000\n",
      "712/712 [==============================] - 1s 722us/step - loss: 0.2551 - accuracy: 0.8926 - val_loss: 0.5180 - val_accuracy: 0.7967\n",
      "Epoch 218/4000\n",
      "712/712 [==============================] - 1s 740us/step - loss: 0.2563 - accuracy: 0.8915 - val_loss: 0.5086 - val_accuracy: 0.7867\n",
      "Epoch 219/4000\n",
      "712/712 [==============================] - 1s 794us/step - loss: 0.2553 - accuracy: 0.8940 - val_loss: 0.5117 - val_accuracy: 0.7884\n",
      "Epoch 220/4000\n",
      "712/712 [==============================] - 1s 712us/step - loss: 0.2551 - accuracy: 0.8912 - val_loss: 0.5098 - val_accuracy: 0.7923\n",
      "Epoch 221/4000\n",
      "712/712 [==============================] - 1s 741us/step - loss: 0.2545 - accuracy: 0.8940 - val_loss: 0.5063 - val_accuracy: 0.7985\n",
      "Epoch 222/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 1s 718us/step - loss: 0.2491 - accuracy: 0.8973 - val_loss: 0.5092 - val_accuracy: 0.7858\n",
      "Epoch 223/4000\n",
      "712/712 [==============================] - 1s 727us/step - loss: 0.2460 - accuracy: 0.8969 - val_loss: 0.5168 - val_accuracy: 0.7967\n",
      "Epoch 224/4000\n",
      "712/712 [==============================] - 1s 706us/step - loss: 0.2469 - accuracy: 0.8972 - val_loss: 0.5457 - val_accuracy: 0.8011\n",
      "Epoch 225/4000\n",
      "712/712 [==============================] - 1s 711us/step - loss: 0.2468 - accuracy: 0.8971 - val_loss: 0.5305 - val_accuracy: 0.8002\n",
      "Epoch 226/4000\n",
      "712/712 [==============================] - 1s 706us/step - loss: 0.2415 - accuracy: 0.8990 - val_loss: 0.5177 - val_accuracy: 0.7916\n",
      "Epoch 227/4000\n",
      "712/712 [==============================] - 1s 732us/step - loss: 0.2413 - accuracy: 0.9001 - val_loss: 0.5157 - val_accuracy: 0.7921\n",
      "Epoch 228/4000\n",
      "712/712 [==============================] - 1s 724us/step - loss: 0.2415 - accuracy: 0.9000 - val_loss: 0.5400 - val_accuracy: 0.7999\n",
      "Epoch 229/4000\n",
      "712/712 [==============================] - 1s 717us/step - loss: 0.2371 - accuracy: 0.9009 - val_loss: 0.5261 - val_accuracy: 0.8000\n",
      "Epoch 230/4000\n",
      "712/712 [==============================] - 1s 718us/step - loss: 0.2394 - accuracy: 0.8995 - val_loss: 0.5290 - val_accuracy: 0.7985\n",
      "Epoch 231/4000\n",
      "712/712 [==============================] - 1s 716us/step - loss: 0.2386 - accuracy: 0.9000 - val_loss: 0.5128 - val_accuracy: 0.7960\n",
      "Epoch 232/4000\n",
      "712/712 [==============================] - 1s 725us/step - loss: 0.2329 - accuracy: 0.9015 - val_loss: 0.5309 - val_accuracy: 0.8014\n",
      "Epoch 233/4000\n",
      "712/712 [==============================] - 1s 715us/step - loss: 0.2354 - accuracy: 0.9027 - val_loss: 0.5264 - val_accuracy: 0.7981\n",
      "Epoch 234/4000\n",
      "712/712 [==============================] - 1s 721us/step - loss: 0.2294 - accuracy: 0.9040 - val_loss: 0.5313 - val_accuracy: 0.7967\n",
      "Epoch 235/4000\n",
      "712/712 [==============================] - 1s 726us/step - loss: 0.2342 - accuracy: 0.9025 - val_loss: 0.5259 - val_accuracy: 0.7993\n",
      "Epoch 236/4000\n",
      "712/712 [==============================] - 1s 725us/step - loss: 0.2286 - accuracy: 0.9041 - val_loss: 0.5394 - val_accuracy: 0.7941\n",
      "Epoch 237/4000\n",
      "712/712 [==============================] - 1s 727us/step - loss: 0.2279 - accuracy: 0.9048 - val_loss: 0.5382 - val_accuracy: 0.8002\n",
      "Epoch 238/4000\n",
      "712/712 [==============================] - 1s 715us/step - loss: 0.2260 - accuracy: 0.9054 - val_loss: 0.5257 - val_accuracy: 0.7942\n",
      "Epoch 239/4000\n",
      "712/712 [==============================] - 1s 715us/step - loss: 0.2243 - accuracy: 0.9078 - val_loss: 0.5235 - val_accuracy: 0.7983\n",
      "Epoch 240/4000\n",
      "712/712 [==============================] - 1s 721us/step - loss: 0.2249 - accuracy: 0.9053 - val_loss: 0.5322 - val_accuracy: 0.7976\n",
      "Epoch 241/4000\n",
      "712/712 [==============================] - 1s 723us/step - loss: 0.2265 - accuracy: 0.9061 - val_loss: 0.5341 - val_accuracy: 0.7937\n",
      "Epoch 242/4000\n",
      "712/712 [==============================] - 1s 730us/step - loss: 0.2215 - accuracy: 0.9084 - val_loss: 0.5197 - val_accuracy: 0.7946\n",
      "Epoch 243/4000\n",
      "712/712 [==============================] - 1s 722us/step - loss: 0.2237 - accuracy: 0.9070 - val_loss: 0.5831 - val_accuracy: 0.8013\n",
      "Epoch 244/4000\n",
      "712/712 [==============================] - 1s 709us/step - loss: 0.2172 - accuracy: 0.9109 - val_loss: 0.5372 - val_accuracy: 0.7999\n",
      "Epoch 245/4000\n",
      "712/712 [==============================] - 1s 708us/step - loss: 0.2165 - accuracy: 0.9137 - val_loss: 0.5222 - val_accuracy: 0.7955\n",
      "Epoch 246/4000\n",
      "712/712 [==============================] - 1s 710us/step - loss: 0.2182 - accuracy: 0.9118 - val_loss: 0.5361 - val_accuracy: 0.7795\n",
      "Epoch 247/4000\n",
      "712/712 [==============================] - 1s 769us/step - loss: 0.2156 - accuracy: 0.9114 - val_loss: 0.5331 - val_accuracy: 0.7876\n",
      "Epoch 248/4000\n",
      "712/712 [==============================] - 1s 770us/step - loss: 0.2131 - accuracy: 0.9129 - val_loss: 0.5354 - val_accuracy: 0.7963\n",
      "Epoch 249/4000\n",
      "712/712 [==============================] - 1s 860us/step - loss: 0.2146 - accuracy: 0.9107 - val_loss: 0.5337 - val_accuracy: 0.7953\n",
      "Epoch 250/4000\n",
      "712/712 [==============================] - 1s 846us/step - loss: 0.2121 - accuracy: 0.9128 - val_loss: 0.5357 - val_accuracy: 0.7932\n",
      "Epoch 251/4000\n",
      "712/712 [==============================] - 1s 745us/step - loss: 0.2076 - accuracy: 0.9157 - val_loss: 0.5409 - val_accuracy: 0.8027\n",
      "Epoch 252/4000\n",
      "712/712 [==============================] - 1s 772us/step - loss: 0.2124 - accuracy: 0.9122 - val_loss: 0.5396 - val_accuracy: 0.7944\n",
      "Epoch 253/4000\n",
      "712/712 [==============================] - 1s 762us/step - loss: 0.2098 - accuracy: 0.9133 - val_loss: 0.5397 - val_accuracy: 0.7930\n",
      "Epoch 254/4000\n",
      "712/712 [==============================] - 1s 797us/step - loss: 0.2088 - accuracy: 0.9143 - val_loss: 0.5341 - val_accuracy: 0.7920\n",
      "Epoch 255/4000\n",
      "712/712 [==============================] - 1s 849us/step - loss: 0.2074 - accuracy: 0.9154 - val_loss: 0.5710 - val_accuracy: 0.8000\n",
      "Epoch 256/4000\n",
      "712/712 [==============================] - 1s 877us/step - loss: 0.2048 - accuracy: 0.9149 - val_loss: 0.5410 - val_accuracy: 0.8014\n",
      "Epoch 257/4000\n",
      "712/712 [==============================] - 1s 815us/step - loss: 0.2081 - accuracy: 0.9110 - val_loss: 0.5476 - val_accuracy: 0.7978\n",
      "Epoch 258/4000\n",
      "712/712 [==============================] - 1s 756us/step - loss: 0.2056 - accuracy: 0.9166 - val_loss: 0.5367 - val_accuracy: 0.7909\n",
      "Epoch 259/4000\n",
      "712/712 [==============================] - 1s 773us/step - loss: 0.2033 - accuracy: 0.9174 - val_loss: 0.5488 - val_accuracy: 0.7897\n",
      "Epoch 260/4000\n",
      "712/712 [==============================] - 1s 745us/step - loss: 0.2005 - accuracy: 0.9181 - val_loss: 0.5553 - val_accuracy: 0.8032\n",
      "Epoch 261/4000\n",
      "712/712 [==============================] - 1s 749us/step - loss: 0.1956 - accuracy: 0.9203 - val_loss: 0.5664 - val_accuracy: 0.7941\n",
      "Epoch 262/4000\n",
      "712/712 [==============================] - 1s 740us/step - loss: 0.1923 - accuracy: 0.9202 - val_loss: 0.5756 - val_accuracy: 0.8025\n",
      "Epoch 263/4000\n",
      "712/712 [==============================] - 1s 738us/step - loss: 0.1983 - accuracy: 0.9199 - val_loss: 0.5631 - val_accuracy: 0.8011\n",
      "Epoch 264/4000\n",
      "712/712 [==============================] - 1s 728us/step - loss: 0.1937 - accuracy: 0.9201 - val_loss: 0.5538 - val_accuracy: 0.7971\n",
      "Epoch 265/4000\n",
      "712/712 [==============================] - 1s 731us/step - loss: 0.1915 - accuracy: 0.9224 - val_loss: 0.5665 - val_accuracy: 0.7993\n",
      "Epoch 266/4000\n",
      "712/712 [==============================] - 1s 747us/step - loss: 0.1939 - accuracy: 0.9197 - val_loss: 0.5603 - val_accuracy: 0.7733\n",
      "Epoch 267/4000\n",
      "712/712 [==============================] - 1s 740us/step - loss: 0.1951 - accuracy: 0.9198 - val_loss: 0.5499 - val_accuracy: 0.7913\n",
      "Epoch 268/4000\n",
      "712/712 [==============================] - 1s 763us/step - loss: 0.1913 - accuracy: 0.9218 - val_loss: 0.5624 - val_accuracy: 0.7978\n",
      "Epoch 269/4000\n",
      "712/712 [==============================] - 1s 761us/step - loss: 0.1885 - accuracy: 0.9240 - val_loss: 0.5602 - val_accuracy: 0.7923\n",
      "Epoch 270/4000\n",
      "712/712 [==============================] - 1s 761us/step - loss: 0.1872 - accuracy: 0.9242 - val_loss: 0.5616 - val_accuracy: 0.8025\n",
      "Epoch 271/4000\n",
      "712/712 [==============================] - 1s 763us/step - loss: 0.1849 - accuracy: 0.9252 - val_loss: 0.5561 - val_accuracy: 0.7955\n",
      "Epoch 272/4000\n",
      "712/712 [==============================] - 1s 779us/step - loss: 0.1887 - accuracy: 0.9227 - val_loss: 0.5484 - val_accuracy: 0.7930\n",
      "Epoch 273/4000\n",
      "712/712 [==============================] - 1s 777us/step - loss: 0.1862 - accuracy: 0.9232 - val_loss: 0.6311 - val_accuracy: 0.8028\n",
      "Epoch 274/4000\n",
      "712/712 [==============================] - 1s 763us/step - loss: 0.1875 - accuracy: 0.9220 - val_loss: 0.5804 - val_accuracy: 0.7930\n",
      "Epoch 275/4000\n",
      "712/712 [==============================] - 1s 759us/step - loss: 0.1813 - accuracy: 0.9264 - val_loss: 0.5677 - val_accuracy: 0.7960\n",
      "Epoch 276/4000\n",
      "712/712 [==============================] - 1s 761us/step - loss: 0.1861 - accuracy: 0.9238 - val_loss: 0.5810 - val_accuracy: 0.8011\n",
      "Epoch 277/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 1s 766us/step - loss: 0.1803 - accuracy: 0.9265 - val_loss: 0.5685 - val_accuracy: 0.7992\n",
      "Epoch 278/4000\n",
      "712/712 [==============================] - 1s 807us/step - loss: 0.1824 - accuracy: 0.9285 - val_loss: 0.5910 - val_accuracy: 0.8035\n",
      "Epoch 279/4000\n",
      "712/712 [==============================] - 1s 822us/step - loss: 0.1811 - accuracy: 0.9266 - val_loss: 0.5555 - val_accuracy: 0.7911\n",
      "Epoch 280/4000\n",
      "712/712 [==============================] - 1s 740us/step - loss: 0.1818 - accuracy: 0.9255 - val_loss: 0.5648 - val_accuracy: 0.7976\n",
      "Epoch 281/4000\n",
      "712/712 [==============================] - 1s 763us/step - loss: 0.1801 - accuracy: 0.9278 - val_loss: 0.5624 - val_accuracy: 0.7848\n",
      "Epoch 282/4000\n",
      "712/712 [==============================] - 1s 755us/step - loss: 0.1793 - accuracy: 0.9268 - val_loss: 0.5729 - val_accuracy: 0.7969\n",
      "Epoch 283/4000\n",
      "712/712 [==============================] - 1s 769us/step - loss: 0.1749 - accuracy: 0.9310 - val_loss: 0.5706 - val_accuracy: 0.7935\n",
      "Epoch 284/4000\n",
      "712/712 [==============================] - 1s 749us/step - loss: 0.1735 - accuracy: 0.9311 - val_loss: 0.5659 - val_accuracy: 0.7890\n",
      "Epoch 285/4000\n",
      "712/712 [==============================] - 1s 772us/step - loss: 0.1751 - accuracy: 0.9284 - val_loss: 0.5766 - val_accuracy: 0.7986\n",
      "Epoch 286/4000\n",
      "712/712 [==============================] - 1s 758us/step - loss: 0.1713 - accuracy: 0.9335 - val_loss: 0.6250 - val_accuracy: 0.8007\n",
      "Epoch 287/4000\n",
      "712/712 [==============================] - 1s 789us/step - loss: 0.1730 - accuracy: 0.9303 - val_loss: 0.5660 - val_accuracy: 0.7993\n",
      "Epoch 288/4000\n",
      "712/712 [==============================] - 1s 770us/step - loss: 0.1723 - accuracy: 0.9297 - val_loss: 0.6037 - val_accuracy: 0.8035\n",
      "Epoch 289/4000\n",
      "712/712 [==============================] - 1s 780us/step - loss: 0.1720 - accuracy: 0.9305 - val_loss: 0.5921 - val_accuracy: 0.8050\n",
      "Epoch 290/4000\n",
      "712/712 [==============================] - 1s 777us/step - loss: 0.1765 - accuracy: 0.9260 - val_loss: 0.5719 - val_accuracy: 0.7972\n",
      "Epoch 291/4000\n",
      "712/712 [==============================] - 1s 779us/step - loss: 0.1676 - accuracy: 0.9315 - val_loss: 0.5831 - val_accuracy: 0.7941\n",
      "Epoch 292/4000\n",
      "712/712 [==============================] - 1s 775us/step - loss: 0.1648 - accuracy: 0.9340 - val_loss: 0.5737 - val_accuracy: 0.7997\n",
      "Epoch 293/4000\n",
      "712/712 [==============================] - 1s 776us/step - loss: 0.1660 - accuracy: 0.9333 - val_loss: 0.5966 - val_accuracy: 0.8032\n",
      "Epoch 294/4000\n",
      "712/712 [==============================] - 1s 766us/step - loss: 0.1685 - accuracy: 0.9328 - val_loss: 0.6161 - val_accuracy: 0.8030\n",
      "Epoch 295/4000\n",
      "712/712 [==============================] - 1s 770us/step - loss: 0.1663 - accuracy: 0.9345 - val_loss: 0.6067 - val_accuracy: 0.7983\n",
      "Epoch 296/4000\n",
      "712/712 [==============================] - 1s 778us/step - loss: 0.1683 - accuracy: 0.9324 - val_loss: 0.6207 - val_accuracy: 0.8074\n",
      "Epoch 297/4000\n",
      "712/712 [==============================] - 1s 786us/step - loss: 0.1653 - accuracy: 0.9321 - val_loss: 0.6437 - val_accuracy: 0.8042\n",
      "Epoch 298/4000\n",
      "712/712 [==============================] - 1s 777us/step - loss: 0.1644 - accuracy: 0.9341 - val_loss: 0.5836 - val_accuracy: 0.7978\n",
      "Epoch 299/4000\n",
      "712/712 [==============================] - 1s 782us/step - loss: 0.1582 - accuracy: 0.9370 - val_loss: 0.6017 - val_accuracy: 0.7993\n",
      "Epoch 300/4000\n",
      "712/712 [==============================] - 1s 766us/step - loss: 0.1605 - accuracy: 0.9365 - val_loss: 0.6019 - val_accuracy: 0.7988\n",
      "Epoch 301/4000\n",
      "712/712 [==============================] - 1s 776us/step - loss: 0.1577 - accuracy: 0.9370 - val_loss: 0.6317 - val_accuracy: 0.7999\n",
      "Epoch 302/4000\n",
      "712/712 [==============================] - 1s 803us/step - loss: 0.1620 - accuracy: 0.9351 - val_loss: 0.5996 - val_accuracy: 0.8053\n",
      "Epoch 303/4000\n",
      "712/712 [==============================] - 1s 791us/step - loss: 0.1558 - accuracy: 0.9399 - val_loss: 0.6059 - val_accuracy: 0.7972\n",
      "Epoch 304/4000\n",
      "712/712 [==============================] - 1s 735us/step - loss: 0.1589 - accuracy: 0.9356 - val_loss: 0.6168 - val_accuracy: 0.8067\n",
      "Epoch 305/4000\n",
      "712/712 [==============================] - 1s 722us/step - loss: 0.1603 - accuracy: 0.9351 - val_loss: 0.6432 - val_accuracy: 0.8034\n",
      "Epoch 306/4000\n",
      "712/712 [==============================] - 1s 720us/step - loss: 0.1593 - accuracy: 0.9372 - val_loss: 0.5980 - val_accuracy: 0.8057\n",
      "Epoch 307/4000\n",
      "712/712 [==============================] - 1s 780us/step - loss: 0.1519 - accuracy: 0.9397 - val_loss: 0.5875 - val_accuracy: 0.8021\n",
      "Epoch 308/4000\n",
      "712/712 [==============================] - 1s 797us/step - loss: 0.1550 - accuracy: 0.9363 - val_loss: 0.6024 - val_accuracy: 0.8060\n",
      "Epoch 309/4000\n",
      "712/712 [==============================] - 1s 757us/step - loss: 0.1580 - accuracy: 0.9376 - val_loss: 0.5825 - val_accuracy: 0.8018\n",
      "Epoch 310/4000\n",
      "712/712 [==============================] - 1s 719us/step - loss: 0.1530 - accuracy: 0.9398 - val_loss: 0.6010 - val_accuracy: 0.7932\n",
      "Epoch 311/4000\n",
      "712/712 [==============================] - 1s 721us/step - loss: 0.1510 - accuracy: 0.9412 - val_loss: 0.5876 - val_accuracy: 0.7913\n",
      "Epoch 312/4000\n",
      "712/712 [==============================] - 1s 729us/step - loss: 0.1514 - accuracy: 0.9393 - val_loss: 0.6328 - val_accuracy: 0.8041\n",
      "Epoch 313/4000\n",
      "712/712 [==============================] - 1s 718us/step - loss: 0.1471 - accuracy: 0.9426 - val_loss: 0.5973 - val_accuracy: 0.7986\n",
      "Epoch 314/4000\n",
      "712/712 [==============================] - 1s 717us/step - loss: 0.1549 - accuracy: 0.9372 - val_loss: 0.6000 - val_accuracy: 0.7911\n",
      "Epoch 315/4000\n",
      "712/712 [==============================] - 1s 719us/step - loss: 0.1489 - accuracy: 0.9404 - val_loss: 0.6057 - val_accuracy: 0.7969\n",
      "Epoch 316/4000\n",
      "712/712 [==============================] - 1s 752us/step - loss: 0.1515 - accuracy: 0.9398 - val_loss: 0.6138 - val_accuracy: 0.8002\n",
      "Epoch 317/4000\n",
      "712/712 [==============================] - 1s 750us/step - loss: 0.1511 - accuracy: 0.9398 - val_loss: 0.6097 - val_accuracy: 0.7992\n",
      "Epoch 318/4000\n",
      "712/712 [==============================] - 1s 744us/step - loss: 0.1432 - accuracy: 0.9432 - val_loss: 0.5940 - val_accuracy: 0.8007\n",
      "Epoch 319/4000\n",
      "712/712 [==============================] - 1s 727us/step - loss: 0.1474 - accuracy: 0.9417 - val_loss: 0.6071 - val_accuracy: 0.7951\n",
      "Epoch 320/4000\n",
      "712/712 [==============================] - 1s 723us/step - loss: 0.1434 - accuracy: 0.9443 - val_loss: 0.5991 - val_accuracy: 0.7978\n",
      "Epoch 321/4000\n",
      "712/712 [==============================] - 1s 731us/step - loss: 0.1443 - accuracy: 0.9436 - val_loss: 0.6015 - val_accuracy: 0.7955\n",
      "Epoch 322/4000\n",
      "712/712 [==============================] - 1s 763us/step - loss: 0.1470 - accuracy: 0.9398 - val_loss: 0.6151 - val_accuracy: 0.7995\n",
      "Epoch 323/4000\n",
      "712/712 [==============================] - 1s 748us/step - loss: 0.1478 - accuracy: 0.9416 - val_loss: 0.6312 - val_accuracy: 0.8039\n",
      "Epoch 324/4000\n",
      "712/712 [==============================] - 1s 738us/step - loss: 0.1442 - accuracy: 0.9424 - val_loss: 0.6053 - val_accuracy: 0.7918\n",
      "Epoch 325/4000\n",
      "712/712 [==============================] - 1s 747us/step - loss: 0.1381 - accuracy: 0.9455 - val_loss: 0.6230 - val_accuracy: 0.8007\n",
      "Epoch 326/4000\n",
      "712/712 [==============================] - 1s 742us/step - loss: 0.1369 - accuracy: 0.9461 - val_loss: 0.6316 - val_accuracy: 0.8057\n",
      "Epoch 327/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.1448 - accuracy: 0.9433 - val_loss: 0.5972 - val_accuracy: 0.7890\n",
      "Epoch 328/4000\n",
      "712/712 [==============================] - 1s 727us/step - loss: 0.1379 - accuracy: 0.9482 - val_loss: 0.6459 - val_accuracy: 0.8025\n",
      "Epoch 329/4000\n",
      "712/712 [==============================] - 1s 742us/step - loss: 0.1375 - accuracy: 0.9462 - val_loss: 0.6258 - val_accuracy: 0.7963\n",
      "Epoch 330/4000\n",
      "712/712 [==============================] - 1s 718us/step - loss: 0.1385 - accuracy: 0.9466 - val_loss: 0.6509 - val_accuracy: 0.8055\n",
      "Epoch 331/4000\n",
      "712/712 [==============================] - 1s 738us/step - loss: 0.1368 - accuracy: 0.9469 - val_loss: 0.6305 - val_accuracy: 0.8032\n",
      "Epoch 332/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 1s 718us/step - loss: 0.1385 - accuracy: 0.9464 - val_loss: 0.7048 - val_accuracy: 0.8060\n",
      "Epoch 333/4000\n",
      "712/712 [==============================] - 1s 715us/step - loss: 0.1378 - accuracy: 0.9443 - val_loss: 0.6324 - val_accuracy: 0.8028\n",
      "Epoch 334/4000\n",
      "712/712 [==============================] - 1s 707us/step - loss: 0.1351 - accuracy: 0.9460 - val_loss: 0.6071 - val_accuracy: 0.8000\n",
      "Epoch 335/4000\n",
      "712/712 [==============================] - 1s 716us/step - loss: 0.1365 - accuracy: 0.9458 - val_loss: 0.6490 - val_accuracy: 0.8011\n",
      "Epoch 336/4000\n",
      "712/712 [==============================] - 1s 718us/step - loss: 0.1361 - accuracy: 0.9478 - val_loss: 0.6234 - val_accuracy: 0.7916\n",
      "Epoch 337/4000\n",
      "712/712 [==============================] - 1s 721us/step - loss: 0.1350 - accuracy: 0.9477 - val_loss: 0.6203 - val_accuracy: 0.7911\n",
      "Epoch 338/4000\n",
      "712/712 [==============================] - 1s 790us/step - loss: 0.1338 - accuracy: 0.9481 - val_loss: 0.6201 - val_accuracy: 0.8009\n",
      "Epoch 339/4000\n",
      "712/712 [==============================] - 1s 744us/step - loss: 0.1330 - accuracy: 0.9467 - val_loss: 0.6710 - val_accuracy: 0.8057\n",
      "Epoch 340/4000\n",
      "712/712 [==============================] - 1s 717us/step - loss: 0.1307 - accuracy: 0.9486 - val_loss: 0.6487 - val_accuracy: 0.8058\n",
      "Epoch 341/4000\n",
      "712/712 [==============================] - 1s 745us/step - loss: 0.1342 - accuracy: 0.9478 - val_loss: 0.6255 - val_accuracy: 0.7971\n",
      "Epoch 342/4000\n",
      "712/712 [==============================] - 1s 715us/step - loss: 0.1321 - accuracy: 0.9472 - val_loss: 0.6414 - val_accuracy: 0.8025\n",
      "Epoch 343/4000\n",
      "712/712 [==============================] - 1s 715us/step - loss: 0.1300 - accuracy: 0.9507 - val_loss: 0.6546 - val_accuracy: 0.7948\n",
      "Epoch 344/4000\n",
      "712/712 [==============================] - 1s 719us/step - loss: 0.1282 - accuracy: 0.9508 - val_loss: 0.6566 - val_accuracy: 0.8046\n",
      "Epoch 345/4000\n",
      "712/712 [==============================] - 1s 723us/step - loss: 0.1279 - accuracy: 0.9509 - val_loss: 0.6357 - val_accuracy: 0.8064\n",
      "Epoch 346/4000\n",
      "712/712 [==============================] - 1s 715us/step - loss: 0.1290 - accuracy: 0.9495 - val_loss: 0.6459 - val_accuracy: 0.8064\n",
      "Epoch 347/4000\n",
      "712/712 [==============================] - 1s 742us/step - loss: 0.1236 - accuracy: 0.9538 - val_loss: 0.6490 - val_accuracy: 0.8014\n",
      "Epoch 348/4000\n",
      "712/712 [==============================] - 1s 775us/step - loss: 0.1270 - accuracy: 0.9504 - val_loss: 0.6460 - val_accuracy: 0.8018\n",
      "Epoch 349/4000\n",
      "712/712 [==============================] - 1s 762us/step - loss: 0.1305 - accuracy: 0.9497 - val_loss: 0.7031 - val_accuracy: 0.8050\n",
      "Epoch 350/4000\n",
      "712/712 [==============================] - 1s 775us/step - loss: 0.1281 - accuracy: 0.9494 - val_loss: 0.6506 - val_accuracy: 0.8004\n",
      "Epoch 351/4000\n",
      "712/712 [==============================] - 1s 800us/step - loss: 0.1263 - accuracy: 0.9515 - val_loss: 0.6735 - val_accuracy: 0.8002\n",
      "Epoch 352/4000\n",
      "712/712 [==============================] - 1s 794us/step - loss: 0.1245 - accuracy: 0.9520 - val_loss: 0.6738 - val_accuracy: 0.8081\n",
      "Epoch 00352: early stopping\n",
      "Training Accuracy: 0.983, Testing Accuracy: 0.808\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NN Model for outcome probability prediction\n",
    "\n",
    "# tuning parameters\n",
    "learning_rate = 0.001\n",
    "\n",
    "# model Architecture\n",
    "outcomeLayers = [keras.layers.Dense(256, activation='relu', input_dim=nFeature),\n",
    "                 keras.layers.Dropout(0.2),\n",
    "                 keras.layers.Dense(128, activation='relu'),\n",
    "                 keras.layers.Dropout(0.2),\n",
    "                 keras.layers.Dense(1, activation='sigmoid')\n",
    "                ]\n",
    "outcomeModel = keras.Sequential(outcomeLayers)\n",
    "\n",
    "# compile model\n",
    "sgd = keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.8) # stochastic gradient descent as optimizer\n",
    "adam = keras.optimizers.Adam(learning_rate=learning_rate) #stochastic gradient descent method based on adaptive \n",
    "                                                          #estimation of 1st order and 2nd order moments\n",
    "outcomeModel.compile(loss='binary_crossentropy',\n",
    "                     optimizer=sgd, \n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "# Early Stopping based on validation loss\n",
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=200)\n",
    "mc = keras.callbacks.ModelCheckpoint('best_model.SB', monitor='val_loss', mode='min', verbose=0, save_best_only=True)\n",
    "\n",
    "historyData = outcomeModel.fit(X_train, Y_outcome_train, validation_data=(X_test, Y_outcome_test),\n",
    "                               epochs=4000,\n",
    "                               callbacks=[es], \n",
    "                               verbose=1)\n",
    "\n",
    "_, train_acc = outcomeModel.evaluate(X_train, Y_outcome_train, verbose=0)\n",
    "_, test_acc = outcomeModel.evaluate(X_test, Y_outcome_test, verbose=0)\n",
    "print('Training Accuracy: %.3f, Testing Accuracy: %.3f' % (train_acc, test_acc))\n",
    "\n",
    "plt.plot(historyData.history['loss'], label='train')\n",
    "plt.plot(historyData.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.title('Loss over time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4d1b816-a355-4519-a67c-9ecfd48f5fd3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      "712/712 [==============================] - 1s 880us/step - loss: 2.3413 - accuracy: 0.1423 - val_loss: 2.1184 - val_accuracy: 0.3100\n",
      "Epoch 2/4000\n",
      "712/712 [==============================] - 1s 766us/step - loss: 2.0004 - accuracy: 0.2935 - val_loss: 1.6954 - val_accuracy: 0.4098\n",
      "Epoch 3/4000\n",
      "712/712 [==============================] - 1s 740us/step - loss: 1.7193 - accuracy: 0.3895 - val_loss: 1.5266 - val_accuracy: 0.4517\n",
      "Epoch 4/4000\n",
      "712/712 [==============================] - 1s 735us/step - loss: 1.5659 - accuracy: 0.4353 - val_loss: 1.3771 - val_accuracy: 0.5044\n",
      "Epoch 5/4000\n",
      "712/712 [==============================] - 1s 737us/step - loss: 1.4798 - accuracy: 0.4652 - val_loss: 1.2560 - val_accuracy: 0.5402\n",
      "Epoch 6/4000\n",
      "712/712 [==============================] - 1s 748us/step - loss: 1.3974 - accuracy: 0.4860 - val_loss: 1.2510 - val_accuracy: 0.5402\n",
      "Epoch 7/4000\n",
      "712/712 [==============================] - 1s 742us/step - loss: 1.3297 - accuracy: 0.5091 - val_loss: 1.1541 - val_accuracy: 0.5762\n",
      "Epoch 8/4000\n",
      "712/712 [==============================] - 1s 751us/step - loss: 1.2835 - accuracy: 0.5256 - val_loss: 1.0824 - val_accuracy: 0.6043\n",
      "Epoch 9/4000\n",
      "712/712 [==============================] - 1s 750us/step - loss: 1.2340 - accuracy: 0.5446 - val_loss: 1.1869 - val_accuracy: 0.5565\n",
      "Epoch 10/4000\n",
      "712/712 [==============================] - 1s 738us/step - loss: 1.1893 - accuracy: 0.5629 - val_loss: 0.9802 - val_accuracy: 0.6310\n",
      "Epoch 11/4000\n",
      "712/712 [==============================] - 1s 770us/step - loss: 1.1515 - accuracy: 0.5739 - val_loss: 1.0044 - val_accuracy: 0.6304\n",
      "Epoch 12/4000\n",
      "712/712 [==============================] - 1s 762us/step - loss: 1.1080 - accuracy: 0.5860 - val_loss: 1.0155 - val_accuracy: 0.6264\n",
      "Epoch 13/4000\n",
      "712/712 [==============================] - 1s 758us/step - loss: 1.0781 - accuracy: 0.6017 - val_loss: 0.8922 - val_accuracy: 0.6661\n",
      "Epoch 14/4000\n",
      "712/712 [==============================] - 1s 819us/step - loss: 1.0447 - accuracy: 0.6115 - val_loss: 0.9058 - val_accuracy: 0.6538\n",
      "Epoch 15/4000\n",
      "712/712 [==============================] - 1s 774us/step - loss: 1.0063 - accuracy: 0.6258 - val_loss: 0.8444 - val_accuracy: 0.6680\n",
      "Epoch 16/4000\n",
      "712/712 [==============================] - 1s 728us/step - loss: 0.9797 - accuracy: 0.6346 - val_loss: 0.8398 - val_accuracy: 0.6763\n",
      "Epoch 17/4000\n",
      "712/712 [==============================] - 1s 729us/step - loss: 0.9536 - accuracy: 0.6445 - val_loss: 0.7861 - val_accuracy: 0.6982\n",
      "Epoch 18/4000\n",
      "712/712 [==============================] - 1s 729us/step - loss: 0.9174 - accuracy: 0.6558 - val_loss: 0.7975 - val_accuracy: 0.6958\n",
      "Epoch 19/4000\n",
      "712/712 [==============================] - 1s 730us/step - loss: 0.8934 - accuracy: 0.6670 - val_loss: 0.8073 - val_accuracy: 0.6835\n",
      "Epoch 20/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.8731 - accuracy: 0.6724 - val_loss: 0.7767 - val_accuracy: 0.7010\n",
      "Epoch 21/4000\n",
      "712/712 [==============================] - 1s 734us/step - loss: 0.8571 - accuracy: 0.6772 - val_loss: 0.7347 - val_accuracy: 0.7131\n",
      "Epoch 22/4000\n",
      "712/712 [==============================] - 1s 734us/step - loss: 0.8331 - accuracy: 0.6869 - val_loss: 0.7664 - val_accuracy: 0.6943\n",
      "Epoch 23/4000\n",
      "712/712 [==============================] - 1s 728us/step - loss: 0.8187 - accuracy: 0.6947 - val_loss: 0.6806 - val_accuracy: 0.7302\n",
      "Epoch 24/4000\n",
      "712/712 [==============================] - 1s 729us/step - loss: 0.8000 - accuracy: 0.6953 - val_loss: 0.7228 - val_accuracy: 0.7137\n",
      "Epoch 25/4000\n",
      "712/712 [==============================] - 1s 747us/step - loss: 0.7755 - accuracy: 0.7039 - val_loss: 0.6456 - val_accuracy: 0.7353\n",
      "Epoch 26/4000\n",
      "712/712 [==============================] - 1s 747us/step - loss: 0.7617 - accuracy: 0.7087 - val_loss: 0.6729 - val_accuracy: 0.7270\n",
      "Epoch 27/4000\n",
      "712/712 [==============================] - 1s 729us/step - loss: 0.7531 - accuracy: 0.7144 - val_loss: 0.6443 - val_accuracy: 0.7405\n",
      "Epoch 28/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.7332 - accuracy: 0.7198 - val_loss: 0.6703 - val_accuracy: 0.7281\n",
      "Epoch 29/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.7245 - accuracy: 0.7213 - val_loss: 0.6305 - val_accuracy: 0.7470\n",
      "Epoch 30/4000\n",
      "712/712 [==============================] - 1s 736us/step - loss: 0.7141 - accuracy: 0.7227 - val_loss: 0.5987 - val_accuracy: 0.7353\n",
      "Epoch 31/4000\n",
      "712/712 [==============================] - 1s 751us/step - loss: 0.6985 - accuracy: 0.7334 - val_loss: 0.5927 - val_accuracy: 0.7542\n",
      "Epoch 32/4000\n",
      "712/712 [==============================] - 1s 803us/step - loss: 0.6798 - accuracy: 0.7345 - val_loss: 0.6412 - val_accuracy: 0.7272\n",
      "Epoch 33/4000\n",
      "712/712 [==============================] - 1s 773us/step - loss: 0.6829 - accuracy: 0.7343 - val_loss: 0.6290 - val_accuracy: 0.7307\n",
      "Epoch 34/4000\n",
      "712/712 [==============================] - 1s 745us/step - loss: 0.6559 - accuracy: 0.7410 - val_loss: 0.6399 - val_accuracy: 0.7163\n",
      "Epoch 35/4000\n",
      "712/712 [==============================] - 1s 742us/step - loss: 0.6527 - accuracy: 0.7443 - val_loss: 0.6338 - val_accuracy: 0.7252\n",
      "Epoch 36/4000\n",
      "712/712 [==============================] - 1s 749us/step - loss: 0.6573 - accuracy: 0.7380 - val_loss: 0.6039 - val_accuracy: 0.7344\n",
      "Epoch 37/4000\n",
      "712/712 [==============================] - 1s 752us/step - loss: 0.6377 - accuracy: 0.7456 - val_loss: 0.5560 - val_accuracy: 0.7597\n",
      "Epoch 38/4000\n",
      "712/712 [==============================] - 1s 751us/step - loss: 0.6248 - accuracy: 0.7518 - val_loss: 0.5453 - val_accuracy: 0.7647\n",
      "Epoch 39/4000\n",
      "712/712 [==============================] - 1s 751us/step - loss: 0.6175 - accuracy: 0.7542 - val_loss: 0.5428 - val_accuracy: 0.7625\n",
      "Epoch 40/4000\n",
      "712/712 [==============================] - 1s 752us/step - loss: 0.6209 - accuracy: 0.7543 - val_loss: 0.5852 - val_accuracy: 0.7451\n",
      "Epoch 41/4000\n",
      "712/712 [==============================] - 1s 745us/step - loss: 0.6325 - accuracy: 0.7513 - val_loss: 0.6317 - val_accuracy: 0.7233\n",
      "Epoch 42/4000\n",
      "712/712 [==============================] - 1s 729us/step - loss: 0.6105 - accuracy: 0.7583 - val_loss: 0.5438 - val_accuracy: 0.7528\n",
      "Epoch 43/4000\n",
      "712/712 [==============================] - 1s 735us/step - loss: 0.6020 - accuracy: 0.7603 - val_loss: 0.5534 - val_accuracy: 0.7525\n",
      "Epoch 44/4000\n",
      "712/712 [==============================] - 1s 828us/step - loss: 0.5920 - accuracy: 0.7606 - val_loss: 0.6181 - val_accuracy: 0.7256\n",
      "Epoch 45/4000\n",
      "712/712 [==============================] - 1s 779us/step - loss: 0.5818 - accuracy: 0.7622 - val_loss: 0.5900 - val_accuracy: 0.7379\n",
      "Epoch 46/4000\n",
      "712/712 [==============================] - 1s 745us/step - loss: 0.5828 - accuracy: 0.7649 - val_loss: 0.5214 - val_accuracy: 0.7621\n",
      "Epoch 47/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.5791 - accuracy: 0.7654 - val_loss: 0.5162 - val_accuracy: 0.7707\n",
      "Epoch 48/4000\n",
      "712/712 [==============================] - 1s 743us/step - loss: 0.5780 - accuracy: 0.7713 - val_loss: 0.5221 - val_accuracy: 0.7572\n",
      "Epoch 49/4000\n",
      "712/712 [==============================] - 1s 736us/step - loss: 0.5714 - accuracy: 0.7658 - val_loss: 0.5516 - val_accuracy: 0.7475\n",
      "Epoch 50/4000\n",
      "712/712 [==============================] - 1s 755us/step - loss: 0.5489 - accuracy: 0.7714 - val_loss: 0.5373 - val_accuracy: 0.7588\n",
      "Epoch 51/4000\n",
      "712/712 [==============================] - 1s 736us/step - loss: 0.5577 - accuracy: 0.7764 - val_loss: 0.5068 - val_accuracy: 0.7656\n",
      "Epoch 52/4000\n",
      "712/712 [==============================] - 1s 758us/step - loss: 0.5420 - accuracy: 0.7746 - val_loss: 0.4972 - val_accuracy: 0.7667\n",
      "Epoch 53/4000\n",
      "712/712 [==============================] - 1s 745us/step - loss: 0.5387 - accuracy: 0.7818 - val_loss: 0.5130 - val_accuracy: 0.7677\n",
      "Epoch 54/4000\n",
      "712/712 [==============================] - 1s 763us/step - loss: 0.5362 - accuracy: 0.7804 - val_loss: 0.4815 - val_accuracy: 0.7735\n",
      "Epoch 55/4000\n",
      "712/712 [==============================] - 1s 741us/step - loss: 0.5401 - accuracy: 0.7820 - val_loss: 0.4905 - val_accuracy: 0.7742\n",
      "Epoch 56/4000\n",
      "712/712 [==============================] - 1s 744us/step - loss: 0.5198 - accuracy: 0.7888 - val_loss: 0.4819 - val_accuracy: 0.7809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/4000\n",
      "712/712 [==============================] - 1s 737us/step - loss: 0.5302 - accuracy: 0.7855 - val_loss: 0.5285 - val_accuracy: 0.7570\n",
      "Epoch 58/4000\n",
      "712/712 [==============================] - 1s 729us/step - loss: 0.5309 - accuracy: 0.7843 - val_loss: 0.5122 - val_accuracy: 0.7560\n",
      "Epoch 59/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.5541 - accuracy: 0.7780 - val_loss: 0.4866 - val_accuracy: 0.7723\n",
      "Epoch 60/4000\n",
      "712/712 [==============================] - 1s 735us/step - loss: 0.5375 - accuracy: 0.7830 - val_loss: 0.4777 - val_accuracy: 0.7798\n",
      "Epoch 61/4000\n",
      "712/712 [==============================] - 1s 833us/step - loss: 0.5205 - accuracy: 0.7859 - val_loss: 0.4920 - val_accuracy: 0.7716\n",
      "Epoch 62/4000\n",
      "712/712 [==============================] - 1s 955us/step - loss: 0.5207 - accuracy: 0.7892 - val_loss: 0.4934 - val_accuracy: 0.7739\n",
      "Epoch 63/4000\n",
      "712/712 [==============================] - 1s 835us/step - loss: 0.5183 - accuracy: 0.7874 - val_loss: 0.4822 - val_accuracy: 0.7735\n",
      "Epoch 64/4000\n",
      "712/712 [==============================] - 1s 782us/step - loss: 0.5136 - accuracy: 0.7929 - val_loss: 0.4723 - val_accuracy: 0.7751\n",
      "Epoch 65/4000\n",
      "712/712 [==============================] - 1s 798us/step - loss: 0.5164 - accuracy: 0.7929 - val_loss: 0.4845 - val_accuracy: 0.7674\n",
      "Epoch 66/4000\n",
      "712/712 [==============================] - 1s 821us/step - loss: 0.5215 - accuracy: 0.7890 - val_loss: 0.4860 - val_accuracy: 0.7748\n",
      "Epoch 67/4000\n",
      "712/712 [==============================] - 1s 846us/step - loss: 0.5181 - accuracy: 0.7924 - val_loss: 0.5088 - val_accuracy: 0.7633\n",
      "Epoch 68/4000\n",
      "712/712 [==============================] - 1s 838us/step - loss: 0.5034 - accuracy: 0.7974 - val_loss: 0.5125 - val_accuracy: 0.7593\n",
      "Epoch 69/4000\n",
      "712/712 [==============================] - 1s 835us/step - loss: 0.5164 - accuracy: 0.7925 - val_loss: 0.4744 - val_accuracy: 0.7814\n",
      "Epoch 70/4000\n",
      "712/712 [==============================] - 1s 843us/step - loss: 0.5288 - accuracy: 0.7897 - val_loss: 0.4838 - val_accuracy: 0.7879\n",
      "Epoch 71/4000\n",
      "712/712 [==============================] - 1s 807us/step - loss: 0.5225 - accuracy: 0.7922 - val_loss: 0.4845 - val_accuracy: 0.7811\n",
      "Epoch 72/4000\n",
      "712/712 [==============================] - 1s 825us/step - loss: 0.5184 - accuracy: 0.7940 - val_loss: 0.5773 - val_accuracy: 0.7547\n",
      "Epoch 73/4000\n",
      "712/712 [==============================] - 1s 860us/step - loss: 0.5364 - accuracy: 0.7909 - val_loss: 0.5448 - val_accuracy: 0.7482\n",
      "Epoch 74/4000\n",
      "712/712 [==============================] - 1s 810us/step - loss: 0.5307 - accuracy: 0.7949 - val_loss: 0.5008 - val_accuracy: 0.7732\n",
      "Epoch 75/4000\n",
      "712/712 [==============================] - 1s 797us/step - loss: 0.5274 - accuracy: 0.7959 - val_loss: 0.4560 - val_accuracy: 0.7934\n",
      "Epoch 76/4000\n",
      "712/712 [==============================] - 1s 782us/step - loss: 0.5178 - accuracy: 0.7999 - val_loss: 0.4796 - val_accuracy: 0.7823\n",
      "Epoch 77/4000\n",
      "712/712 [==============================] - 1s 778us/step - loss: 0.5411 - accuracy: 0.7926 - val_loss: 0.4915 - val_accuracy: 0.7844\n",
      "Epoch 78/4000\n",
      "712/712 [==============================] - 1s 789us/step - loss: 0.5226 - accuracy: 0.7937 - val_loss: 0.5349 - val_accuracy: 0.7644\n",
      "Epoch 79/4000\n",
      "712/712 [==============================] - 1s 791us/step - loss: 0.5265 - accuracy: 0.7913 - val_loss: 0.4870 - val_accuracy: 0.7839\n",
      "Epoch 80/4000\n",
      "712/712 [==============================] - 1s 773us/step - loss: 0.5203 - accuracy: 0.7954 - val_loss: 0.5078 - val_accuracy: 0.7674\n",
      "Epoch 81/4000\n",
      "712/712 [==============================] - 1s 766us/step - loss: 0.5146 - accuracy: 0.7977 - val_loss: 0.5130 - val_accuracy: 0.7711\n",
      "Epoch 82/4000\n",
      "712/712 [==============================] - 1s 752us/step - loss: 0.5157 - accuracy: 0.7979 - val_loss: 0.4730 - val_accuracy: 0.7818\n",
      "Epoch 83/4000\n",
      "712/712 [==============================] - 1s 759us/step - loss: 0.5112 - accuracy: 0.8006 - val_loss: 0.5302 - val_accuracy: 0.7644\n",
      "Epoch 84/4000\n",
      "712/712 [==============================] - 1s 738us/step - loss: 0.5199 - accuracy: 0.8019 - val_loss: 0.5034 - val_accuracy: 0.7877\n",
      "Epoch 85/4000\n",
      "712/712 [==============================] - 1s 752us/step - loss: 0.5247 - accuracy: 0.7938 - val_loss: 0.5136 - val_accuracy: 0.7669\n",
      "Epoch 86/4000\n",
      "712/712 [==============================] - 1s 798us/step - loss: 0.5167 - accuracy: 0.8010 - val_loss: 0.4639 - val_accuracy: 0.7855\n",
      "Epoch 87/4000\n",
      "712/712 [==============================] - 1s 752us/step - loss: 0.5169 - accuracy: 0.8007 - val_loss: 0.4933 - val_accuracy: 0.7807\n",
      "Epoch 88/4000\n",
      "712/712 [==============================] - 1s 786us/step - loss: 0.5106 - accuracy: 0.8022 - val_loss: 0.4566 - val_accuracy: 0.7911\n",
      "Epoch 89/4000\n",
      "712/712 [==============================] - 1s 772us/step - loss: 0.5192 - accuracy: 0.7960 - val_loss: 0.5015 - val_accuracy: 0.7798\n",
      "Epoch 90/4000\n",
      "712/712 [==============================] - 1s 797us/step - loss: 0.5094 - accuracy: 0.8038 - val_loss: 0.5380 - val_accuracy: 0.7669\n",
      "Epoch 91/4000\n",
      "712/712 [==============================] - 1s 754us/step - loss: 0.5236 - accuracy: 0.7980 - val_loss: 0.4963 - val_accuracy: 0.7795\n",
      "Epoch 92/4000\n",
      "712/712 [==============================] - 1s 740us/step - loss: 0.5124 - accuracy: 0.7998 - val_loss: 0.4571 - val_accuracy: 0.7944\n",
      "Epoch 93/4000\n",
      "712/712 [==============================] - 1s 731us/step - loss: 0.5005 - accuracy: 0.8046 - val_loss: 0.4580 - val_accuracy: 0.7893\n",
      "Epoch 94/4000\n",
      "712/712 [==============================] - 1s 730us/step - loss: 0.5026 - accuracy: 0.8043 - val_loss: 0.4330 - val_accuracy: 0.8004\n",
      "Epoch 95/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.4979 - accuracy: 0.8057 - val_loss: 0.4545 - val_accuracy: 0.7921\n",
      "Epoch 96/4000\n",
      "712/712 [==============================] - 1s 728us/step - loss: 0.4988 - accuracy: 0.8059 - val_loss: 0.4691 - val_accuracy: 0.7932\n",
      "Epoch 97/4000\n",
      "712/712 [==============================] - 1s 737us/step - loss: 0.4857 - accuracy: 0.8101 - val_loss: 0.4450 - val_accuracy: 0.7956\n",
      "Epoch 98/4000\n",
      "712/712 [==============================] - 1s 732us/step - loss: 0.4879 - accuracy: 0.8100 - val_loss: 0.4751 - val_accuracy: 0.7874\n",
      "Epoch 99/4000\n",
      "712/712 [==============================] - 1s 747us/step - loss: 0.4937 - accuracy: 0.8075 - val_loss: 0.4626 - val_accuracy: 0.7920\n",
      "Epoch 100/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.4869 - accuracy: 0.8125 - val_loss: 0.4469 - val_accuracy: 0.7963\n",
      "Epoch 101/4000\n",
      "712/712 [==============================] - 1s 739us/step - loss: 0.4858 - accuracy: 0.8083 - val_loss: 0.4580 - val_accuracy: 0.7899\n",
      "Epoch 102/4000\n",
      "712/712 [==============================] - 1s 869us/step - loss: 0.4732 - accuracy: 0.8171 - val_loss: 0.4597 - val_accuracy: 0.7877\n",
      "Epoch 103/4000\n",
      "712/712 [==============================] - 1s 800us/step - loss: 0.4755 - accuracy: 0.8130 - val_loss: 0.4200 - val_accuracy: 0.8121\n",
      "Epoch 104/4000\n",
      "712/712 [==============================] - 1s 770us/step - loss: 0.4760 - accuracy: 0.8134 - val_loss: 0.4964 - val_accuracy: 0.7714\n",
      "Epoch 105/4000\n",
      "712/712 [==============================] - 1s 762us/step - loss: 0.4820 - accuracy: 0.8147 - val_loss: 0.5019 - val_accuracy: 0.7714\n",
      "Epoch 106/4000\n",
      "712/712 [==============================] - 1s 789us/step - loss: 0.4702 - accuracy: 0.8157 - val_loss: 0.4242 - val_accuracy: 0.8107\n",
      "Epoch 107/4000\n",
      "712/712 [==============================] - 1s 759us/step - loss: 0.4742 - accuracy: 0.8153 - val_loss: 0.4276 - val_accuracy: 0.7983\n",
      "Epoch 108/4000\n",
      "712/712 [==============================] - 1s 758us/step - loss: 0.4696 - accuracy: 0.8157 - val_loss: 0.4511 - val_accuracy: 0.7927\n",
      "Epoch 109/4000\n",
      "712/712 [==============================] - 1s 773us/step - loss: 0.4920 - accuracy: 0.8100 - val_loss: 0.4285 - val_accuracy: 0.7999\n",
      "Epoch 110/4000\n",
      "712/712 [==============================] - 1s 771us/step - loss: 0.4714 - accuracy: 0.8191 - val_loss: 0.4352 - val_accuracy: 0.8030\n",
      "Epoch 111/4000\n",
      "712/712 [==============================] - 1s 760us/step - loss: 0.4970 - accuracy: 0.8107 - val_loss: 0.5082 - val_accuracy: 0.7688\n",
      "Epoch 112/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 1s 728us/step - loss: 0.4909 - accuracy: 0.8145 - val_loss: 0.4917 - val_accuracy: 0.7876\n",
      "Epoch 113/4000\n",
      "712/712 [==============================] - 1s 732us/step - loss: 0.5089 - accuracy: 0.8075 - val_loss: 0.4746 - val_accuracy: 0.7886\n",
      "Epoch 114/4000\n",
      "712/712 [==============================] - 1s 730us/step - loss: 0.5226 - accuracy: 0.8042 - val_loss: 0.5061 - val_accuracy: 0.7755\n",
      "Epoch 115/4000\n",
      "712/712 [==============================] - 1s 738us/step - loss: 0.5236 - accuracy: 0.8068 - val_loss: 0.4718 - val_accuracy: 0.7934\n",
      "Epoch 116/4000\n",
      "712/712 [==============================] - 1s 731us/step - loss: 0.5539 - accuracy: 0.8004 - val_loss: 0.4940 - val_accuracy: 0.7862\n",
      "Epoch 117/4000\n",
      "712/712 [==============================] - 1s 736us/step - loss: 0.5657 - accuracy: 0.7942 - val_loss: 0.4835 - val_accuracy: 0.7909\n",
      "Epoch 118/4000\n",
      "712/712 [==============================] - 1s 752us/step - loss: 0.5635 - accuracy: 0.7938 - val_loss: 0.5094 - val_accuracy: 0.7856\n",
      "Epoch 119/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.5666 - accuracy: 0.7904 - val_loss: 0.4984 - val_accuracy: 0.7746\n",
      "Epoch 120/4000\n",
      "712/712 [==============================] - 1s 731us/step - loss: 0.5804 - accuracy: 0.7884 - val_loss: 0.5234 - val_accuracy: 0.7714\n",
      "Epoch 121/4000\n",
      "712/712 [==============================] - 1s 741us/step - loss: 0.5663 - accuracy: 0.7921 - val_loss: 0.4822 - val_accuracy: 0.7985\n",
      "Epoch 122/4000\n",
      "712/712 [==============================] - 1s 731us/step - loss: 0.5590 - accuracy: 0.7948 - val_loss: 0.4801 - val_accuracy: 0.7902\n",
      "Epoch 123/4000\n",
      "712/712 [==============================] - 1s 738us/step - loss: 0.5510 - accuracy: 0.7972 - val_loss: 0.5007 - val_accuracy: 0.7869\n",
      "Epoch 124/4000\n",
      "712/712 [==============================] - 1s 731us/step - loss: 0.5478 - accuracy: 0.8007 - val_loss: 0.5028 - val_accuracy: 0.7779\n",
      "Epoch 125/4000\n",
      "712/712 [==============================] - 1s 739us/step - loss: 0.5478 - accuracy: 0.8020 - val_loss: 0.4688 - val_accuracy: 0.7965\n",
      "Epoch 126/4000\n",
      "712/712 [==============================] - 1s 736us/step - loss: 0.5398 - accuracy: 0.8016 - val_loss: 0.4740 - val_accuracy: 0.7944\n",
      "Epoch 127/4000\n",
      "712/712 [==============================] - 1s 729us/step - loss: 0.5274 - accuracy: 0.8026 - val_loss: 0.4842 - val_accuracy: 0.7851\n",
      "Epoch 128/4000\n",
      "712/712 [==============================] - 1s 730us/step - loss: 0.5364 - accuracy: 0.8035 - val_loss: 0.4844 - val_accuracy: 0.7906\n",
      "Epoch 129/4000\n",
      "712/712 [==============================] - 1s 735us/step - loss: 0.5225 - accuracy: 0.8032 - val_loss: 0.4738 - val_accuracy: 0.7837\n",
      "Epoch 130/4000\n",
      "712/712 [==============================] - 1s 734us/step - loss: 0.5671 - accuracy: 0.7915 - val_loss: 0.5073 - val_accuracy: 0.7744\n",
      "Epoch 131/4000\n",
      "712/712 [==============================] - 1s 746us/step - loss: 0.5689 - accuracy: 0.7924 - val_loss: 0.5123 - val_accuracy: 0.7719\n",
      "Epoch 132/4000\n",
      "712/712 [==============================] - 1s 810us/step - loss: 0.5500 - accuracy: 0.7955 - val_loss: 0.4898 - val_accuracy: 0.7904\n",
      "Epoch 133/4000\n",
      "712/712 [==============================] - 1s 751us/step - loss: 0.5487 - accuracy: 0.8010 - val_loss: 0.4592 - val_accuracy: 0.7958\n",
      "Epoch 134/4000\n",
      "712/712 [==============================] - 1s 734us/step - loss: 0.5757 - accuracy: 0.7898 - val_loss: 0.4804 - val_accuracy: 0.7884\n",
      "Epoch 135/4000\n",
      "712/712 [==============================] - 1s 738us/step - loss: 0.5737 - accuracy: 0.7887 - val_loss: 0.5377 - val_accuracy: 0.7660\n",
      "Epoch 136/4000\n",
      "712/712 [==============================] - 1s 737us/step - loss: 0.5505 - accuracy: 0.7964 - val_loss: 0.5166 - val_accuracy: 0.7762\n",
      "Epoch 137/4000\n",
      "712/712 [==============================] - 1s 747us/step - loss: 0.5637 - accuracy: 0.7905 - val_loss: 0.4810 - val_accuracy: 0.7942\n",
      "Epoch 138/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.5363 - accuracy: 0.7997 - val_loss: 0.5085 - val_accuracy: 0.7711\n",
      "Epoch 139/4000\n",
      "712/712 [==============================] - 1s 729us/step - loss: 0.5475 - accuracy: 0.7968 - val_loss: 0.4744 - val_accuracy: 0.7953\n",
      "Epoch 140/4000\n",
      "712/712 [==============================] - 1s 739us/step - loss: 0.5354 - accuracy: 0.8024 - val_loss: 0.4664 - val_accuracy: 0.7883\n",
      "Epoch 141/4000\n",
      "712/712 [==============================] - 1s 726us/step - loss: 0.5416 - accuracy: 0.8000 - val_loss: 0.4858 - val_accuracy: 0.7877\n",
      "Epoch 142/4000\n",
      "712/712 [==============================] - 1s 757us/step - loss: 0.5369 - accuracy: 0.8045 - val_loss: 0.4588 - val_accuracy: 0.7974\n",
      "Epoch 143/4000\n",
      "712/712 [==============================] - 1s 745us/step - loss: 0.5296 - accuracy: 0.8006 - val_loss: 0.4662 - val_accuracy: 0.7958\n",
      "Epoch 144/4000\n",
      "712/712 [==============================] - 1s 739us/step - loss: 0.5103 - accuracy: 0.8086 - val_loss: 0.4305 - val_accuracy: 0.7993\n",
      "Epoch 145/4000\n",
      "712/712 [==============================] - 1s 730us/step - loss: 0.5114 - accuracy: 0.8106 - val_loss: 0.4754 - val_accuracy: 0.7867\n",
      "Epoch 146/4000\n",
      "712/712 [==============================] - 1s 732us/step - loss: 0.5156 - accuracy: 0.8049 - val_loss: 0.4839 - val_accuracy: 0.7814\n",
      "Epoch 147/4000\n",
      "712/712 [==============================] - 1s 737us/step - loss: 0.5146 - accuracy: 0.8080 - val_loss: 0.4850 - val_accuracy: 0.7934\n",
      "Epoch 148/4000\n",
      "712/712 [==============================] - 1s 734us/step - loss: 0.5167 - accuracy: 0.8051 - val_loss: 0.4622 - val_accuracy: 0.7913\n",
      "Epoch 149/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.5309 - accuracy: 0.8035 - val_loss: 0.4444 - val_accuracy: 0.7995\n",
      "Epoch 150/4000\n",
      "712/712 [==============================] - 1s 734us/step - loss: 0.5229 - accuracy: 0.8046 - val_loss: 0.4930 - val_accuracy: 0.7962\n",
      "Epoch 151/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.5156 - accuracy: 0.8107 - val_loss: 0.4651 - val_accuracy: 0.7962\n",
      "Epoch 152/4000\n",
      "712/712 [==============================] - 1s 725us/step - loss: 0.5254 - accuracy: 0.8046 - val_loss: 0.4892 - val_accuracy: 0.7827\n",
      "Epoch 153/4000\n",
      "712/712 [==============================] - 1s 726us/step - loss: 0.5181 - accuracy: 0.8084 - val_loss: 0.4416 - val_accuracy: 0.8034\n",
      "Epoch 154/4000\n",
      "712/712 [==============================] - 1s 728us/step - loss: 0.5267 - accuracy: 0.8058 - val_loss: 0.4681 - val_accuracy: 0.7883\n",
      "Epoch 155/4000\n",
      "712/712 [==============================] - 1s 735us/step - loss: 0.5304 - accuracy: 0.8043 - val_loss: 0.4868 - val_accuracy: 0.7888\n",
      "Epoch 156/4000\n",
      "712/712 [==============================] - 1s 747us/step - loss: 0.5243 - accuracy: 0.8057 - val_loss: 0.4589 - val_accuracy: 0.7948\n",
      "Epoch 157/4000\n",
      "712/712 [==============================] - 1s 737us/step - loss: 0.5648 - accuracy: 0.7974 - val_loss: 0.4587 - val_accuracy: 0.8027\n",
      "Epoch 158/4000\n",
      "712/712 [==============================] - 1s 731us/step - loss: 0.5744 - accuracy: 0.7923 - val_loss: 0.4829 - val_accuracy: 0.8004\n",
      "Epoch 159/4000\n",
      "712/712 [==============================] - 1s 738us/step - loss: 0.6098 - accuracy: 0.7824 - val_loss: 0.4833 - val_accuracy: 0.7958\n",
      "Epoch 160/4000\n",
      "712/712 [==============================] - 1s 734us/step - loss: 0.5824 - accuracy: 0.7880 - val_loss: 0.4602 - val_accuracy: 0.8014\n",
      "Epoch 161/4000\n",
      "712/712 [==============================] - 1s 738us/step - loss: 0.6052 - accuracy: 0.7838 - val_loss: 0.5005 - val_accuracy: 0.7907\n",
      "Epoch 162/4000\n",
      "712/712 [==============================] - 1s 803us/step - loss: 0.5757 - accuracy: 0.7921 - val_loss: 0.4905 - val_accuracy: 0.7886\n",
      "Epoch 163/4000\n",
      "712/712 [==============================] - 1s 782us/step - loss: 0.5829 - accuracy: 0.7903 - val_loss: 0.4530 - val_accuracy: 0.8018\n",
      "Epoch 164/4000\n",
      "712/712 [==============================] - 1s 736us/step - loss: 0.5738 - accuracy: 0.7916 - val_loss: 0.4969 - val_accuracy: 0.7863\n",
      "Epoch 165/4000\n",
      "712/712 [==============================] - 1s 746us/step - loss: 0.5737 - accuracy: 0.7951 - val_loss: 0.4676 - val_accuracy: 0.7979\n",
      "Epoch 166/4000\n",
      "712/712 [==============================] - 1s 735us/step - loss: 0.5752 - accuracy: 0.7946 - val_loss: 0.4928 - val_accuracy: 0.7879\n",
      "Epoch 167/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 1s 728us/step - loss: 0.5749 - accuracy: 0.7960 - val_loss: 0.4750 - val_accuracy: 0.7846\n",
      "Epoch 168/4000\n",
      "712/712 [==============================] - 1s 736us/step - loss: 0.5603 - accuracy: 0.7955 - val_loss: 0.4385 - val_accuracy: 0.8074\n",
      "Epoch 169/4000\n",
      "712/712 [==============================] - 1s 726us/step - loss: 0.5736 - accuracy: 0.7937 - val_loss: 0.4463 - val_accuracy: 0.8021\n",
      "Epoch 170/4000\n",
      "712/712 [==============================] - 1s 734us/step - loss: 0.5602 - accuracy: 0.7978 - val_loss: 0.4634 - val_accuracy: 0.7893\n",
      "Epoch 171/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.5590 - accuracy: 0.7971 - val_loss: 0.4733 - val_accuracy: 0.7935\n",
      "Epoch 172/4000\n",
      "712/712 [==============================] - 1s 748us/step - loss: 0.5646 - accuracy: 0.7943 - val_loss: 0.4849 - val_accuracy: 0.7876\n",
      "Epoch 173/4000\n",
      "712/712 [==============================] - 1s 744us/step - loss: 0.5472 - accuracy: 0.7996 - val_loss: 0.4372 - val_accuracy: 0.8037\n",
      "Epoch 174/4000\n",
      "712/712 [==============================] - 1s 734us/step - loss: 0.5408 - accuracy: 0.8016 - val_loss: 0.4585 - val_accuracy: 0.7948\n",
      "Epoch 175/4000\n",
      "712/712 [==============================] - 1s 746us/step - loss: 0.5429 - accuracy: 0.8012 - val_loss: 0.4305 - val_accuracy: 0.8093\n",
      "Epoch 176/4000\n",
      "712/712 [==============================] - 1s 737us/step - loss: 0.5324 - accuracy: 0.8037 - val_loss: 0.4515 - val_accuracy: 0.7999\n",
      "Epoch 177/4000\n",
      "712/712 [==============================] - 1s 726us/step - loss: 0.5381 - accuracy: 0.8061 - val_loss: 0.4469 - val_accuracy: 0.7949\n",
      "Epoch 178/4000\n",
      "712/712 [==============================] - 1s 731us/step - loss: 0.5338 - accuracy: 0.8053 - val_loss: 0.4783 - val_accuracy: 0.7923\n",
      "Epoch 179/4000\n",
      "712/712 [==============================] - 1s 741us/step - loss: 0.5437 - accuracy: 0.8013 - val_loss: 0.4472 - val_accuracy: 0.8021\n",
      "Epoch 180/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.5358 - accuracy: 0.8053 - val_loss: 0.4198 - val_accuracy: 0.8141\n",
      "Epoch 181/4000\n",
      "712/712 [==============================] - 1s 738us/step - loss: 0.5557 - accuracy: 0.7957 - val_loss: 0.4836 - val_accuracy: 0.7911\n",
      "Epoch 182/4000\n",
      "712/712 [==============================] - 1s 735us/step - loss: 0.5635 - accuracy: 0.7957 - val_loss: 0.4568 - val_accuracy: 0.7962\n",
      "Epoch 183/4000\n",
      "712/712 [==============================] - 1s 729us/step - loss: 0.5536 - accuracy: 0.8018 - val_loss: 0.4523 - val_accuracy: 0.7981\n",
      "Epoch 184/4000\n",
      "712/712 [==============================] - 1s 730us/step - loss: 0.5584 - accuracy: 0.7984 - val_loss: 0.4525 - val_accuracy: 0.8086\n",
      "Epoch 185/4000\n",
      "712/712 [==============================] - 1s 731us/step - loss: 0.5528 - accuracy: 0.7977 - val_loss: 0.4108 - val_accuracy: 0.8146\n",
      "Epoch 186/4000\n",
      "712/712 [==============================] - 1s 723us/step - loss: 0.5430 - accuracy: 0.8049 - val_loss: 0.4629 - val_accuracy: 0.7967\n",
      "Epoch 187/4000\n",
      "712/712 [==============================] - 1s 726us/step - loss: 0.5468 - accuracy: 0.8019 - val_loss: 0.4649 - val_accuracy: 0.7911\n",
      "Epoch 188/4000\n",
      "712/712 [==============================] - 1s 732us/step - loss: 0.5441 - accuracy: 0.7992 - val_loss: 0.4623 - val_accuracy: 0.7965\n",
      "Epoch 189/4000\n",
      "712/712 [==============================] - 1s 732us/step - loss: 0.5369 - accuracy: 0.8034 - val_loss: 0.4800 - val_accuracy: 0.7914\n",
      "Epoch 190/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.5674 - accuracy: 0.7933 - val_loss: 0.4529 - val_accuracy: 0.8004\n",
      "Epoch 191/4000\n",
      "712/712 [==============================] - 1s 732us/step - loss: 0.5702 - accuracy: 0.7959 - val_loss: 0.4691 - val_accuracy: 0.7951\n",
      "Epoch 192/4000\n",
      "712/712 [==============================] - 1s 777us/step - loss: 0.5552 - accuracy: 0.7981 - val_loss: 0.4653 - val_accuracy: 0.7937\n",
      "Epoch 193/4000\n",
      "712/712 [==============================] - 1s 812us/step - loss: 0.5647 - accuracy: 0.7974 - val_loss: 0.4656 - val_accuracy: 0.7927\n",
      "Epoch 194/4000\n",
      "712/712 [==============================] - 1s 743us/step - loss: 0.5537 - accuracy: 0.7989 - val_loss: 0.4429 - val_accuracy: 0.8067\n",
      "Epoch 195/4000\n",
      "712/712 [==============================] - 1s 739us/step - loss: 0.5523 - accuracy: 0.8003 - val_loss: 0.4749 - val_accuracy: 0.7965\n",
      "Epoch 196/4000\n",
      "712/712 [==============================] - 1s 729us/step - loss: 0.5348 - accuracy: 0.8038 - val_loss: 0.4295 - val_accuracy: 0.8088\n",
      "Epoch 197/4000\n",
      "712/712 [==============================] - 1s 741us/step - loss: 0.5506 - accuracy: 0.7999 - val_loss: 0.4440 - val_accuracy: 0.8060\n",
      "Epoch 198/4000\n",
      "712/712 [==============================] - 1s 728us/step - loss: 0.5456 - accuracy: 0.7977 - val_loss: 0.4662 - val_accuracy: 0.7862\n",
      "Epoch 199/4000\n",
      "712/712 [==============================] - 1s 754us/step - loss: 0.5273 - accuracy: 0.8024 - val_loss: 0.4564 - val_accuracy: 0.7976\n",
      "Epoch 200/4000\n",
      "712/712 [==============================] - 1s 741us/step - loss: 0.5375 - accuracy: 0.8034 - val_loss: 0.4688 - val_accuracy: 0.7962\n",
      "Epoch 201/4000\n",
      "712/712 [==============================] - 1s 734us/step - loss: 0.5549 - accuracy: 0.7982 - val_loss: 0.4909 - val_accuracy: 0.7848\n",
      "Epoch 202/4000\n",
      "712/712 [==============================] - 1s 731us/step - loss: 0.5576 - accuracy: 0.8019 - val_loss: 0.4602 - val_accuracy: 0.8009\n",
      "Epoch 203/4000\n",
      "712/712 [==============================] - 1s 724us/step - loss: 0.5514 - accuracy: 0.7981 - val_loss: 0.4508 - val_accuracy: 0.8016\n",
      "Epoch 204/4000\n",
      "712/712 [==============================] - 1s 729us/step - loss: 0.5596 - accuracy: 0.7971 - val_loss: 0.4496 - val_accuracy: 0.8079\n",
      "Epoch 205/4000\n",
      "712/712 [==============================] - 1s 735us/step - loss: 0.5462 - accuracy: 0.8026 - val_loss: 0.4503 - val_accuracy: 0.8028\n",
      "Epoch 206/4000\n",
      "712/712 [==============================] - 1s 736us/step - loss: 0.5459 - accuracy: 0.8042 - val_loss: 0.4482 - val_accuracy: 0.8023\n",
      "Epoch 207/4000\n",
      "712/712 [==============================] - 1s 727us/step - loss: 0.5370 - accuracy: 0.8042 - val_loss: 0.4572 - val_accuracy: 0.7971\n",
      "Epoch 208/4000\n",
      "712/712 [==============================] - 1s 730us/step - loss: 0.5462 - accuracy: 0.8014 - val_loss: 0.4532 - val_accuracy: 0.8016\n",
      "Epoch 209/4000\n",
      "712/712 [==============================] - 1s 728us/step - loss: 0.5403 - accuracy: 0.8005 - val_loss: 0.4486 - val_accuracy: 0.7999\n",
      "Epoch 210/4000\n",
      "712/712 [==============================] - 1s 732us/step - loss: 0.5340 - accuracy: 0.8048 - val_loss: 0.4629 - val_accuracy: 0.7913\n",
      "Epoch 211/4000\n",
      "712/712 [==============================] - 1s 720us/step - loss: 0.5231 - accuracy: 0.8089 - val_loss: 0.4630 - val_accuracy: 0.7932\n",
      "Epoch 212/4000\n",
      "712/712 [==============================] - 1s 736us/step - loss: 0.5194 - accuracy: 0.8078 - val_loss: 0.4453 - val_accuracy: 0.8007\n",
      "Epoch 213/4000\n",
      "712/712 [==============================] - 1s 725us/step - loss: 0.5253 - accuracy: 0.8051 - val_loss: 0.4784 - val_accuracy: 0.7823\n",
      "Epoch 214/4000\n",
      "712/712 [==============================] - 1s 750us/step - loss: 0.5250 - accuracy: 0.8073 - val_loss: 0.4490 - val_accuracy: 0.7939\n",
      "Epoch 215/4000\n",
      "712/712 [==============================] - 1s 727us/step - loss: 0.5204 - accuracy: 0.8071 - val_loss: 0.4173 - val_accuracy: 0.8076\n",
      "Epoch 216/4000\n",
      "712/712 [==============================] - 1s 735us/step - loss: 0.5484 - accuracy: 0.8015 - val_loss: 0.4451 - val_accuracy: 0.8050\n",
      "Epoch 217/4000\n",
      "712/712 [==============================] - 1s 730us/step - loss: 0.5800 - accuracy: 0.7933 - val_loss: 0.4471 - val_accuracy: 0.8014\n",
      "Epoch 218/4000\n",
      "712/712 [==============================] - 1s 729us/step - loss: 0.5903 - accuracy: 0.7902 - val_loss: 0.4351 - val_accuracy: 0.8129\n",
      "Epoch 219/4000\n",
      "712/712 [==============================] - 1s 730us/step - loss: 0.5725 - accuracy: 0.7965 - val_loss: 0.4473 - val_accuracy: 0.7988\n",
      "Epoch 220/4000\n",
      "712/712 [==============================] - 1s 752us/step - loss: 0.5690 - accuracy: 0.7962 - val_loss: 0.4404 - val_accuracy: 0.8109\n",
      "Epoch 221/4000\n",
      "712/712 [==============================] - 1s 729us/step - loss: 0.5649 - accuracy: 0.7972 - val_loss: 0.4516 - val_accuracy: 0.8020\n",
      "Epoch 222/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 1s 738us/step - loss: 0.5511 - accuracy: 0.8039 - val_loss: 0.4532 - val_accuracy: 0.8085\n",
      "Epoch 223/4000\n",
      "712/712 [==============================] - 1s 815us/step - loss: 0.5433 - accuracy: 0.8027 - val_loss: 0.4196 - val_accuracy: 0.8178\n",
      "Epoch 224/4000\n",
      "712/712 [==============================] - 1s 751us/step - loss: 0.5575 - accuracy: 0.8012 - val_loss: 0.4255 - val_accuracy: 0.8086\n",
      "Epoch 225/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.5483 - accuracy: 0.8035 - val_loss: 0.4255 - val_accuracy: 0.8048\n",
      "Epoch 226/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.5553 - accuracy: 0.8010 - val_loss: 0.4323 - val_accuracy: 0.8030\n",
      "Epoch 227/4000\n",
      "712/712 [==============================] - 1s 728us/step - loss: 0.5515 - accuracy: 0.8021 - val_loss: 0.4377 - val_accuracy: 0.8085\n",
      "Epoch 228/4000\n",
      "712/712 [==============================] - 1s 732us/step - loss: 0.5781 - accuracy: 0.7965 - val_loss: 0.4316 - val_accuracy: 0.8099\n",
      "Epoch 229/4000\n",
      "712/712 [==============================] - 1s 741us/step - loss: 0.5775 - accuracy: 0.7986 - val_loss: 0.4326 - val_accuracy: 0.8090\n",
      "Epoch 230/4000\n",
      "712/712 [==============================] - 1s 738us/step - loss: 0.5864 - accuracy: 0.7929 - val_loss: 0.4425 - val_accuracy: 0.8127\n",
      "Epoch 231/4000\n",
      "712/712 [==============================] - 1s 732us/step - loss: 0.6056 - accuracy: 0.7906 - val_loss: 0.4539 - val_accuracy: 0.8048\n",
      "Epoch 232/4000\n",
      "712/712 [==============================] - 1s 727us/step - loss: 0.5952 - accuracy: 0.7893 - val_loss: 0.4358 - val_accuracy: 0.8144\n",
      "Epoch 233/4000\n",
      "712/712 [==============================] - 1s 753us/step - loss: 0.5966 - accuracy: 0.7906 - val_loss: 0.4647 - val_accuracy: 0.8062\n",
      "Epoch 234/4000\n",
      "712/712 [==============================] - 1s 729us/step - loss: 0.5819 - accuracy: 0.7977 - val_loss: 0.4489 - val_accuracy: 0.8034\n",
      "Epoch 235/4000\n",
      "712/712 [==============================] - 1s 732us/step - loss: 0.5875 - accuracy: 0.7979 - val_loss: 0.4453 - val_accuracy: 0.8057\n",
      "Epoch 236/4000\n",
      "712/712 [==============================] - 1s 730us/step - loss: 0.5813 - accuracy: 0.7969 - val_loss: 0.4363 - val_accuracy: 0.8143\n",
      "Epoch 237/4000\n",
      "712/712 [==============================] - 1s 730us/step - loss: 0.5713 - accuracy: 0.7974 - val_loss: 0.4383 - val_accuracy: 0.8157\n",
      "Epoch 238/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.5776 - accuracy: 0.7976 - val_loss: 0.4308 - val_accuracy: 0.8158\n",
      "Epoch 239/4000\n",
      "712/712 [==============================] - 1s 795us/step - loss: 0.5806 - accuracy: 0.7944 - val_loss: 0.3972 - val_accuracy: 0.8276\n",
      "Epoch 240/4000\n",
      "712/712 [==============================] - 1s 762us/step - loss: 0.5559 - accuracy: 0.8022 - val_loss: 0.4395 - val_accuracy: 0.8109\n",
      "Epoch 241/4000\n",
      "712/712 [==============================] - 1s 755us/step - loss: 0.5786 - accuracy: 0.7945 - val_loss: 0.5054 - val_accuracy: 0.7927\n",
      "Epoch 242/4000\n",
      "712/712 [==============================] - 1s 758us/step - loss: 0.6118 - accuracy: 0.7892 - val_loss: 0.5088 - val_accuracy: 0.7944\n",
      "Epoch 243/4000\n",
      "712/712 [==============================] - 1s 759us/step - loss: 0.6097 - accuracy: 0.7899 - val_loss: 0.4415 - val_accuracy: 0.8186\n",
      "Epoch 244/4000\n",
      "712/712 [==============================] - 1s 757us/step - loss: 0.6187 - accuracy: 0.7864 - val_loss: 0.4618 - val_accuracy: 0.8069\n",
      "Epoch 245/4000\n",
      "712/712 [==============================] - 1s 758us/step - loss: 0.5892 - accuracy: 0.7930 - val_loss: 0.4602 - val_accuracy: 0.8016\n",
      "Epoch 246/4000\n",
      "712/712 [==============================] - 1s 766us/step - loss: 0.5901 - accuracy: 0.7917 - val_loss: 0.4353 - val_accuracy: 0.8139\n",
      "Epoch 247/4000\n",
      "712/712 [==============================] - 1s 734us/step - loss: 0.5831 - accuracy: 0.7935 - val_loss: 0.4549 - val_accuracy: 0.8106\n",
      "Epoch 248/4000\n",
      "712/712 [==============================] - 1s 760us/step - loss: 0.6196 - accuracy: 0.7863 - val_loss: 0.5033 - val_accuracy: 0.7985\n",
      "Epoch 249/4000\n",
      "712/712 [==============================] - 1s 732us/step - loss: 0.6058 - accuracy: 0.7913 - val_loss: 0.4687 - val_accuracy: 0.7974\n",
      "Epoch 250/4000\n",
      "712/712 [==============================] - 1s 762us/step - loss: 0.6059 - accuracy: 0.7914 - val_loss: 0.4163 - val_accuracy: 0.8248\n",
      "Epoch 251/4000\n",
      "712/712 [==============================] - 1s 768us/step - loss: 0.5976 - accuracy: 0.7950 - val_loss: 0.4256 - val_accuracy: 0.8200\n",
      "Epoch 252/4000\n",
      "712/712 [==============================] - 1s 783us/step - loss: 0.6093 - accuracy: 0.7885 - val_loss: 0.4453 - val_accuracy: 0.8074\n",
      "Epoch 253/4000\n",
      "712/712 [==============================] - 1s 818us/step - loss: 0.6231 - accuracy: 0.7842 - val_loss: 0.4784 - val_accuracy: 0.8044\n",
      "Epoch 254/4000\n",
      "712/712 [==============================] - 1s 757us/step - loss: 0.6227 - accuracy: 0.7822 - val_loss: 0.4388 - val_accuracy: 0.8141\n",
      "Epoch 255/4000\n",
      "712/712 [==============================] - 1s 750us/step - loss: 0.6145 - accuracy: 0.7898 - val_loss: 0.4449 - val_accuracy: 0.8129\n",
      "Epoch 256/4000\n",
      "712/712 [==============================] - 1s 759us/step - loss: 0.6216 - accuracy: 0.7865 - val_loss: 0.4566 - val_accuracy: 0.8132\n",
      "Epoch 257/4000\n",
      "712/712 [==============================] - 1s 755us/step - loss: 0.6096 - accuracy: 0.7885 - val_loss: 0.4843 - val_accuracy: 0.7965\n",
      "Epoch 258/4000\n",
      "712/712 [==============================] - 1s 737us/step - loss: 0.5988 - accuracy: 0.7931 - val_loss: 0.4422 - val_accuracy: 0.8037\n",
      "Epoch 259/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.6097 - accuracy: 0.7892 - val_loss: 0.4572 - val_accuracy: 0.8013\n",
      "Epoch 260/4000\n",
      "712/712 [==============================] - 1s 736us/step - loss: 0.6104 - accuracy: 0.7862 - val_loss: 0.4284 - val_accuracy: 0.8129\n",
      "Epoch 261/4000\n",
      "712/712 [==============================] - 1s 739us/step - loss: 0.6054 - accuracy: 0.7924 - val_loss: 0.4222 - val_accuracy: 0.8200\n",
      "Epoch 262/4000\n",
      "712/712 [==============================] - 1s 736us/step - loss: 0.5855 - accuracy: 0.7980 - val_loss: 0.4115 - val_accuracy: 0.8206\n",
      "Epoch 263/4000\n",
      "712/712 [==============================] - 1s 735us/step - loss: 0.5987 - accuracy: 0.7921 - val_loss: 0.4427 - val_accuracy: 0.8120\n",
      "Epoch 264/4000\n",
      "712/712 [==============================] - 1s 741us/step - loss: 0.6112 - accuracy: 0.7889 - val_loss: 0.4231 - val_accuracy: 0.8222\n",
      "Epoch 265/4000\n",
      "712/712 [==============================] - 1s 735us/step - loss: 0.5826 - accuracy: 0.7960 - val_loss: 0.4365 - val_accuracy: 0.8183\n",
      "Epoch 266/4000\n",
      "712/712 [==============================] - 1s 728us/step - loss: 0.6013 - accuracy: 0.7929 - val_loss: 0.4333 - val_accuracy: 0.8209\n",
      "Epoch 267/4000\n",
      "712/712 [==============================] - 1s 729us/step - loss: 0.5841 - accuracy: 0.7998 - val_loss: 0.4507 - val_accuracy: 0.8123\n",
      "Epoch 268/4000\n",
      "712/712 [==============================] - 1s 729us/step - loss: 0.5802 - accuracy: 0.7964 - val_loss: 0.4543 - val_accuracy: 0.8065\n",
      "Epoch 269/4000\n",
      "712/712 [==============================] - 1s 737us/step - loss: 0.5910 - accuracy: 0.7965 - val_loss: 0.4099 - val_accuracy: 0.8229\n",
      "Epoch 270/4000\n",
      "712/712 [==============================] - 1s 734us/step - loss: 0.5887 - accuracy: 0.7929 - val_loss: 0.4185 - val_accuracy: 0.8193\n",
      "Epoch 271/4000\n",
      "712/712 [==============================] - 1s 749us/step - loss: 0.6105 - accuracy: 0.7851 - val_loss: 0.4618 - val_accuracy: 0.8004\n",
      "Epoch 272/4000\n",
      "712/712 [==============================] - 1s 731us/step - loss: 0.6156 - accuracy: 0.7872 - val_loss: 0.4599 - val_accuracy: 0.8006\n",
      "Epoch 273/4000\n",
      "712/712 [==============================] - 1s 734us/step - loss: 0.6166 - accuracy: 0.7854 - val_loss: 0.4508 - val_accuracy: 0.8136\n",
      "Epoch 274/4000\n",
      "712/712 [==============================] - 1s 727us/step - loss: 0.5993 - accuracy: 0.7924 - val_loss: 0.4374 - val_accuracy: 0.8176\n",
      "Epoch 275/4000\n",
      "712/712 [==============================] - 1s 730us/step - loss: 0.5940 - accuracy: 0.7934 - val_loss: 0.4542 - val_accuracy: 0.8004\n",
      "Epoch 276/4000\n",
      "712/712 [==============================] - 1s 749us/step - loss: 0.5979 - accuracy: 0.7932 - val_loss: 0.4348 - val_accuracy: 0.8060\n",
      "Epoch 277/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 1s 738us/step - loss: 0.5880 - accuracy: 0.7956 - val_loss: 0.4897 - val_accuracy: 0.7860\n",
      "Epoch 278/4000\n",
      "712/712 [==============================] - 1s 734us/step - loss: 0.5949 - accuracy: 0.7952 - val_loss: 0.4197 - val_accuracy: 0.8174\n",
      "Epoch 279/4000\n",
      "712/712 [==============================] - 1s 728us/step - loss: 0.5972 - accuracy: 0.7930 - val_loss: 0.4067 - val_accuracy: 0.8251\n",
      "Epoch 280/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.6002 - accuracy: 0.7943 - val_loss: 0.4364 - val_accuracy: 0.8069\n",
      "Epoch 281/4000\n",
      "712/712 [==============================] - 1s 728us/step - loss: 0.5894 - accuracy: 0.7963 - val_loss: 0.4484 - val_accuracy: 0.7914\n",
      "Epoch 282/4000\n",
      "712/712 [==============================] - 1s 727us/step - loss: 0.5703 - accuracy: 0.7976 - val_loss: 0.4009 - val_accuracy: 0.8285\n",
      "Epoch 283/4000\n",
      "712/712 [==============================] - 1s 808us/step - loss: 0.5788 - accuracy: 0.8009 - val_loss: 0.4370 - val_accuracy: 0.8213\n",
      "Epoch 284/4000\n",
      "712/712 [==============================] - 1s 756us/step - loss: 0.5667 - accuracy: 0.8003 - val_loss: 0.3889 - val_accuracy: 0.8329\n",
      "Epoch 285/4000\n",
      "712/712 [==============================] - 1s 730us/step - loss: 0.5766 - accuracy: 0.7982 - val_loss: 0.4175 - val_accuracy: 0.8211\n",
      "Epoch 286/4000\n",
      "712/712 [==============================] - 1s 732us/step - loss: 0.5912 - accuracy: 0.7973 - val_loss: 0.4830 - val_accuracy: 0.7983\n",
      "Epoch 287/4000\n",
      "712/712 [==============================] - 1s 734us/step - loss: 0.6238 - accuracy: 0.7824 - val_loss: 0.4613 - val_accuracy: 0.8079\n",
      "Epoch 288/4000\n",
      "712/712 [==============================] - 1s 755us/step - loss: 0.6079 - accuracy: 0.7899 - val_loss: 0.4508 - val_accuracy: 0.8130\n",
      "Epoch 289/4000\n",
      "712/712 [==============================] - 1s 727us/step - loss: 0.5944 - accuracy: 0.7977 - val_loss: 0.4380 - val_accuracy: 0.8144\n",
      "Epoch 290/4000\n",
      "712/712 [==============================] - 1s 750us/step - loss: 0.6058 - accuracy: 0.7911 - val_loss: 0.3904 - val_accuracy: 0.8383\n",
      "Epoch 291/4000\n",
      "712/712 [==============================] - 1s 737us/step - loss: 0.5935 - accuracy: 0.7964 - val_loss: 0.3944 - val_accuracy: 0.8367\n",
      "Epoch 292/4000\n",
      "712/712 [==============================] - 1s 757us/step - loss: 0.5912 - accuracy: 0.7970 - val_loss: 0.4120 - val_accuracy: 0.8306\n",
      "Epoch 293/4000\n",
      "712/712 [==============================] - 1s 731us/step - loss: 0.5861 - accuracy: 0.8006 - val_loss: 0.4023 - val_accuracy: 0.8344\n",
      "Epoch 294/4000\n",
      "712/712 [==============================] - 1s 722us/step - loss: 0.5896 - accuracy: 0.7971 - val_loss: 0.4351 - val_accuracy: 0.8116\n",
      "Epoch 295/4000\n",
      "712/712 [==============================] - 1s 747us/step - loss: 0.5831 - accuracy: 0.7991 - val_loss: 0.3852 - val_accuracy: 0.8409\n",
      "Epoch 296/4000\n",
      "712/712 [==============================] - 1s 736us/step - loss: 0.5875 - accuracy: 0.7978 - val_loss: 0.4184 - val_accuracy: 0.8199\n",
      "Epoch 297/4000\n",
      "712/712 [==============================] - 1s 731us/step - loss: 0.5774 - accuracy: 0.8014 - val_loss: 0.4082 - val_accuracy: 0.8278\n",
      "Epoch 298/4000\n",
      "712/712 [==============================] - 1s 728us/step - loss: 0.5762 - accuracy: 0.7994 - val_loss: 0.4154 - val_accuracy: 0.8253\n",
      "Epoch 299/4000\n",
      "712/712 [==============================] - 1s 740us/step - loss: 0.5825 - accuracy: 0.8003 - val_loss: 0.3997 - val_accuracy: 0.8308\n",
      "Epoch 300/4000\n",
      "712/712 [==============================] - 1s 734us/step - loss: 0.5770 - accuracy: 0.8046 - val_loss: 0.5550 - val_accuracy: 0.7749\n",
      "Epoch 301/4000\n",
      "712/712 [==============================] - 1s 737us/step - loss: 0.6092 - accuracy: 0.7888 - val_loss: 0.5414 - val_accuracy: 0.7726\n",
      "Epoch 302/4000\n",
      "712/712 [==============================] - 1s 729us/step - loss: 0.6075 - accuracy: 0.7861 - val_loss: 0.4703 - val_accuracy: 0.7942\n",
      "Epoch 303/4000\n",
      "712/712 [==============================] - 1s 736us/step - loss: 0.5920 - accuracy: 0.7983 - val_loss: 0.4847 - val_accuracy: 0.8127\n",
      "Epoch 304/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.6695 - accuracy: 0.7759 - val_loss: 0.5280 - val_accuracy: 0.7927\n",
      "Epoch 305/4000\n",
      "712/712 [==============================] - 1s 732us/step - loss: 0.6344 - accuracy: 0.7797 - val_loss: 0.4639 - val_accuracy: 0.8169\n",
      "Epoch 306/4000\n",
      "712/712 [==============================] - 1s 744us/step - loss: 0.6464 - accuracy: 0.7781 - val_loss: 0.4819 - val_accuracy: 0.8013\n",
      "Epoch 307/4000\n",
      "712/712 [==============================] - 1s 744us/step - loss: 0.6449 - accuracy: 0.7805 - val_loss: 0.4742 - val_accuracy: 0.8107\n",
      "Epoch 308/4000\n",
      "712/712 [==============================] - 1s 741us/step - loss: 0.6464 - accuracy: 0.7763 - val_loss: 0.4595 - val_accuracy: 0.8211\n",
      "Epoch 309/4000\n",
      "712/712 [==============================] - 1s 755us/step - loss: 0.6363 - accuracy: 0.7833 - val_loss: 0.4571 - val_accuracy: 0.8076\n",
      "Epoch 310/4000\n",
      "712/712 [==============================] - 1s 742us/step - loss: 0.6263 - accuracy: 0.7840 - val_loss: 0.5180 - val_accuracy: 0.7862\n",
      "Epoch 311/4000\n",
      "712/712 [==============================] - 1s 735us/step - loss: 0.6536 - accuracy: 0.7794 - val_loss: 0.4609 - val_accuracy: 0.8121\n",
      "Epoch 312/4000\n",
      "712/712 [==============================] - 1s 737us/step - loss: 0.6646 - accuracy: 0.7717 - val_loss: 0.4645 - val_accuracy: 0.7993\n",
      "Epoch 313/4000\n",
      "712/712 [==============================] - 1s 831us/step - loss: 0.6653 - accuracy: 0.7712 - val_loss: 0.4629 - val_accuracy: 0.8236\n",
      "Epoch 314/4000\n",
      "712/712 [==============================] - 1s 791us/step - loss: 0.6253 - accuracy: 0.7857 - val_loss: 0.4165 - val_accuracy: 0.8262\n",
      "Epoch 315/4000\n",
      "712/712 [==============================] - 1s 739us/step - loss: 0.5994 - accuracy: 0.7919 - val_loss: 0.4292 - val_accuracy: 0.8216\n",
      "Epoch 316/4000\n",
      "712/712 [==============================] - 1s 740us/step - loss: 0.6120 - accuracy: 0.7870 - val_loss: 0.4780 - val_accuracy: 0.7932\n",
      "Epoch 317/4000\n",
      "712/712 [==============================] - 1s 732us/step - loss: 0.6025 - accuracy: 0.7893 - val_loss: 0.4438 - val_accuracy: 0.8162\n",
      "Epoch 318/4000\n",
      "712/712 [==============================] - 1s 749us/step - loss: 0.5985 - accuracy: 0.7917 - val_loss: 0.4406 - val_accuracy: 0.8169\n",
      "Epoch 319/4000\n",
      "712/712 [==============================] - 1s 726us/step - loss: 0.5926 - accuracy: 0.7934 - val_loss: 0.4400 - val_accuracy: 0.8211\n",
      "Epoch 320/4000\n",
      "712/712 [==============================] - 1s 726us/step - loss: 0.5820 - accuracy: 0.7910 - val_loss: 0.4851 - val_accuracy: 0.7714\n",
      "Epoch 321/4000\n",
      "712/712 [==============================] - 1s 735us/step - loss: 0.6286 - accuracy: 0.7824 - val_loss: 0.4437 - val_accuracy: 0.8190\n",
      "Epoch 322/4000\n",
      "712/712 [==============================] - 1s 740us/step - loss: 0.6388 - accuracy: 0.7780 - val_loss: 0.4709 - val_accuracy: 0.8155\n",
      "Epoch 323/4000\n",
      "712/712 [==============================] - 1s 782us/step - loss: 0.6652 - accuracy: 0.7758 - val_loss: 0.4338 - val_accuracy: 0.8234\n",
      "Epoch 324/4000\n",
      "712/712 [==============================] - 1s 781us/step - loss: 0.6677 - accuracy: 0.7727 - val_loss: 0.4497 - val_accuracy: 0.8179\n",
      "Epoch 325/4000\n",
      "712/712 [==============================] - 1s 778us/step - loss: 0.7087 - accuracy: 0.7587 - val_loss: 0.5591 - val_accuracy: 0.7798\n",
      "Epoch 326/4000\n",
      "712/712 [==============================] - 1s 763us/step - loss: 0.6988 - accuracy: 0.7633 - val_loss: 0.5113 - val_accuracy: 0.7863\n",
      "Epoch 327/4000\n",
      "712/712 [==============================] - 1s 754us/step - loss: 0.7071 - accuracy: 0.7570 - val_loss: 0.5038 - val_accuracy: 0.7921\n",
      "Epoch 328/4000\n",
      "712/712 [==============================] - 1s 772us/step - loss: 0.6925 - accuracy: 0.7622 - val_loss: 0.4699 - val_accuracy: 0.8011\n",
      "Epoch 329/4000\n",
      "712/712 [==============================] - 1s 756us/step - loss: 0.7024 - accuracy: 0.7574 - val_loss: 0.4806 - val_accuracy: 0.8048\n",
      "Epoch 330/4000\n",
      "712/712 [==============================] - 1s 752us/step - loss: 0.6814 - accuracy: 0.7676 - val_loss: 0.4456 - val_accuracy: 0.8157\n",
      "Epoch 331/4000\n",
      "712/712 [==============================] - 1s 744us/step - loss: 0.6812 - accuracy: 0.7651 - val_loss: 0.4581 - val_accuracy: 0.8141\n",
      "Epoch 332/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 1s 759us/step - loss: 0.6693 - accuracy: 0.7698 - val_loss: 0.4620 - val_accuracy: 0.8129\n",
      "Epoch 333/4000\n",
      "712/712 [==============================] - 1s 735us/step - loss: 0.6729 - accuracy: 0.7730 - val_loss: 0.4601 - val_accuracy: 0.8121\n",
      "Epoch 334/4000\n",
      "712/712 [==============================] - 1s 742us/step - loss: 0.6573 - accuracy: 0.7730 - val_loss: 0.5001 - val_accuracy: 0.7781\n",
      "Epoch 335/4000\n",
      "712/712 [==============================] - 1s 737us/step - loss: 0.7049 - accuracy: 0.7608 - val_loss: 0.4733 - val_accuracy: 0.8097\n",
      "Epoch 336/4000\n",
      "712/712 [==============================] - 1s 740us/step - loss: 0.6829 - accuracy: 0.7666 - val_loss: 0.4979 - val_accuracy: 0.7981\n",
      "Epoch 337/4000\n",
      "712/712 [==============================] - 1s 735us/step - loss: 0.6791 - accuracy: 0.7684 - val_loss: 0.4490 - val_accuracy: 0.8143\n",
      "Epoch 338/4000\n",
      "712/712 [==============================] - 1s 738us/step - loss: 0.6928 - accuracy: 0.7636 - val_loss: 0.4464 - val_accuracy: 0.8151\n",
      "Epoch 339/4000\n",
      "712/712 [==============================] - 1s 735us/step - loss: 0.6723 - accuracy: 0.7715 - val_loss: 0.4914 - val_accuracy: 0.7990\n",
      "Epoch 340/4000\n",
      "712/712 [==============================] - 1s 740us/step - loss: 0.6768 - accuracy: 0.7670 - val_loss: 0.4998 - val_accuracy: 0.7921\n",
      "Epoch 341/4000\n",
      "712/712 [==============================] - 1s 727us/step - loss: 0.6680 - accuracy: 0.7714 - val_loss: 0.4422 - val_accuracy: 0.8208\n",
      "Epoch 342/4000\n",
      "712/712 [==============================] - 1s 737us/step - loss: 0.6583 - accuracy: 0.7749 - val_loss: 0.5508 - val_accuracy: 0.7744\n",
      "Epoch 343/4000\n",
      "712/712 [==============================] - 1s 804us/step - loss: 0.6751 - accuracy: 0.7719 - val_loss: 0.4690 - val_accuracy: 0.8044\n",
      "Epoch 344/4000\n",
      "712/712 [==============================] - 1s 767us/step - loss: 0.6843 - accuracy: 0.7662 - val_loss: 0.4412 - val_accuracy: 0.8130\n",
      "Epoch 345/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.6675 - accuracy: 0.7741 - val_loss: 0.4482 - val_accuracy: 0.8209\n",
      "Epoch 346/4000\n",
      "712/712 [==============================] - 1s 729us/step - loss: 0.6624 - accuracy: 0.7780 - val_loss: 0.4445 - val_accuracy: 0.8218\n",
      "Epoch 347/4000\n",
      "712/712 [==============================] - 1s 748us/step - loss: 0.6610 - accuracy: 0.7758 - val_loss: 0.4623 - val_accuracy: 0.8074\n",
      "Epoch 348/4000\n",
      "712/712 [==============================] - 1s 734us/step - loss: 0.6480 - accuracy: 0.7793 - val_loss: 0.4386 - val_accuracy: 0.8095\n",
      "Epoch 349/4000\n",
      "712/712 [==============================] - 1s 731us/step - loss: 0.6484 - accuracy: 0.7775 - val_loss: 0.4387 - val_accuracy: 0.8192\n",
      "Epoch 350/4000\n",
      "712/712 [==============================] - 1s 738us/step - loss: 0.6542 - accuracy: 0.7769 - val_loss: 0.4606 - val_accuracy: 0.8083\n",
      "Epoch 351/4000\n",
      "712/712 [==============================] - 1s 748us/step - loss: 0.6475 - accuracy: 0.7820 - val_loss: 0.4650 - val_accuracy: 0.7985\n",
      "Epoch 352/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.6382 - accuracy: 0.7819 - val_loss: 0.4242 - val_accuracy: 0.8218\n",
      "Epoch 353/4000\n",
      "712/712 [==============================] - 1s 734us/step - loss: 0.7333 - accuracy: 0.7546 - val_loss: 0.5357 - val_accuracy: 0.7963\n",
      "Epoch 354/4000\n",
      "712/712 [==============================] - 1s 738us/step - loss: 0.7305 - accuracy: 0.7561 - val_loss: 0.5687 - val_accuracy: 0.7814\n",
      "Epoch 355/4000\n",
      "712/712 [==============================] - 1s 736us/step - loss: 0.7206 - accuracy: 0.7601 - val_loss: 0.5293 - val_accuracy: 0.7846\n",
      "Epoch 356/4000\n",
      "712/712 [==============================] - 1s 732us/step - loss: 0.7183 - accuracy: 0.7618 - val_loss: 0.5121 - val_accuracy: 0.7993\n",
      "Epoch 357/4000\n",
      "712/712 [==============================] - 1s 744us/step - loss: 0.7003 - accuracy: 0.7649 - val_loss: 0.5170 - val_accuracy: 0.7932\n",
      "Epoch 358/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.7050 - accuracy: 0.7659 - val_loss: 0.4980 - val_accuracy: 0.8013\n",
      "Epoch 359/4000\n",
      "712/712 [==============================] - 1s 740us/step - loss: 0.7032 - accuracy: 0.7640 - val_loss: 0.5185 - val_accuracy: 0.8018\n",
      "Epoch 360/4000\n",
      "712/712 [==============================] - 1s 730us/step - loss: 0.7051 - accuracy: 0.7632 - val_loss: 0.5073 - val_accuracy: 0.8078\n",
      "Epoch 361/4000\n",
      "712/712 [==============================] - 1s 736us/step - loss: 0.7036 - accuracy: 0.7636 - val_loss: 0.5111 - val_accuracy: 0.8025\n",
      "Epoch 362/4000\n",
      "712/712 [==============================] - 1s 738us/step - loss: 0.6990 - accuracy: 0.7692 - val_loss: 0.5550 - val_accuracy: 0.7899\n",
      "Epoch 363/4000\n",
      "712/712 [==============================] - 1s 738us/step - loss: 0.6878 - accuracy: 0.7716 - val_loss: 0.5106 - val_accuracy: 0.8021\n",
      "Epoch 364/4000\n",
      "712/712 [==============================] - 1s 731us/step - loss: 0.6890 - accuracy: 0.7692 - val_loss: 0.4993 - val_accuracy: 0.7993\n",
      "Epoch 365/4000\n",
      "712/712 [==============================] - 1s 732us/step - loss: 0.6925 - accuracy: 0.7660 - val_loss: 0.4811 - val_accuracy: 0.8088\n",
      "Epoch 366/4000\n",
      "712/712 [==============================] - 1s 756us/step - loss: 0.6762 - accuracy: 0.7762 - val_loss: 0.5159 - val_accuracy: 0.8013\n",
      "Epoch 367/4000\n",
      "712/712 [==============================] - 1s 738us/step - loss: 0.6695 - accuracy: 0.7747 - val_loss: 0.4782 - val_accuracy: 0.8057\n",
      "Epoch 368/4000\n",
      "712/712 [==============================] - 1s 728us/step - loss: 0.6709 - accuracy: 0.7749 - val_loss: 0.5091 - val_accuracy: 0.7928\n",
      "Epoch 369/4000\n",
      "712/712 [==============================] - 1s 757us/step - loss: 0.6560 - accuracy: 0.7812 - val_loss: 0.4901 - val_accuracy: 0.8099\n",
      "Epoch 370/4000\n",
      "712/712 [==============================] - 1s 760us/step - loss: 0.6635 - accuracy: 0.7817 - val_loss: 0.4634 - val_accuracy: 0.8169\n",
      "Epoch 371/4000\n",
      "712/712 [==============================] - 1s 746us/step - loss: 0.6597 - accuracy: 0.7795 - val_loss: 0.4499 - val_accuracy: 0.8185\n",
      "Epoch 372/4000\n",
      "712/712 [==============================] - 1s 737us/step - loss: 0.6558 - accuracy: 0.7773 - val_loss: 0.4422 - val_accuracy: 0.8272\n",
      "Epoch 373/4000\n",
      "712/712 [==============================] - 1s 791us/step - loss: 0.6371 - accuracy: 0.7841 - val_loss: 0.4446 - val_accuracy: 0.8174\n",
      "Epoch 374/4000\n",
      "712/712 [==============================] - 1s 796us/step - loss: 0.6740 - accuracy: 0.7751 - val_loss: 0.4524 - val_accuracy: 0.8250\n",
      "Epoch 375/4000\n",
      "712/712 [==============================] - 1s 739us/step - loss: 0.6441 - accuracy: 0.7787 - val_loss: 0.4545 - val_accuracy: 0.8218\n",
      "Epoch 376/4000\n",
      "712/712 [==============================] - 1s 739us/step - loss: 0.6939 - accuracy: 0.7682 - val_loss: 0.5790 - val_accuracy: 0.7809\n",
      "Epoch 377/4000\n",
      "712/712 [==============================] - 1s 736us/step - loss: 0.7487 - accuracy: 0.7543 - val_loss: 0.5581 - val_accuracy: 0.7937\n",
      "Epoch 378/4000\n",
      "712/712 [==============================] - 1s 728us/step - loss: 0.7290 - accuracy: 0.7581 - val_loss: 0.5297 - val_accuracy: 0.8039\n",
      "Epoch 379/4000\n",
      "712/712 [==============================] - 1s 731us/step - loss: 0.7293 - accuracy: 0.7556 - val_loss: 0.5290 - val_accuracy: 0.8030\n",
      "Epoch 380/4000\n",
      "712/712 [==============================] - 1s 737us/step - loss: 0.7219 - accuracy: 0.7604 - val_loss: 0.5058 - val_accuracy: 0.8125\n",
      "Epoch 381/4000\n",
      "712/712 [==============================] - 1s 731us/step - loss: 0.7259 - accuracy: 0.7588 - val_loss: 0.5314 - val_accuracy: 0.7942\n",
      "Epoch 382/4000\n",
      "712/712 [==============================] - 1s 731us/step - loss: 0.7182 - accuracy: 0.7584 - val_loss: 0.5315 - val_accuracy: 0.8062\n",
      "Epoch 383/4000\n",
      "712/712 [==============================] - 1s 735us/step - loss: 0.7085 - accuracy: 0.7604 - val_loss: 0.5501 - val_accuracy: 0.8037\n",
      "Epoch 384/4000\n",
      "712/712 [==============================] - 1s 732us/step - loss: 0.7199 - accuracy: 0.7610 - val_loss: 0.5619 - val_accuracy: 0.7979\n",
      "Epoch 385/4000\n",
      "712/712 [==============================] - 1s 754us/step - loss: 0.7467 - accuracy: 0.7535 - val_loss: 0.5518 - val_accuracy: 0.8032\n",
      "Epoch 386/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.7950 - accuracy: 0.7401 - val_loss: 0.5609 - val_accuracy: 0.8004\n",
      "Epoch 387/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 1s 745us/step - loss: 0.8070 - accuracy: 0.7405 - val_loss: 0.5743 - val_accuracy: 0.7909\n",
      "Epoch 388/4000\n",
      "712/712 [==============================] - 1s 739us/step - loss: 0.7913 - accuracy: 0.7419 - val_loss: 0.6032 - val_accuracy: 0.7730\n",
      "Epoch 389/4000\n",
      "712/712 [==============================] - 1s 750us/step - loss: 0.7937 - accuracy: 0.7417 - val_loss: 0.5819 - val_accuracy: 0.7937\n",
      "Epoch 390/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.7914 - accuracy: 0.7428 - val_loss: 0.5477 - val_accuracy: 0.8037\n",
      "Epoch 391/4000\n",
      "712/712 [==============================] - 1s 739us/step - loss: 0.7980 - accuracy: 0.7412 - val_loss: 0.5705 - val_accuracy: 0.7928\n",
      "Epoch 392/4000\n",
      "712/712 [==============================] - 1s 732us/step - loss: 0.7802 - accuracy: 0.7463 - val_loss: 0.5238 - val_accuracy: 0.8037\n",
      "Epoch 393/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.7708 - accuracy: 0.7461 - val_loss: 0.5435 - val_accuracy: 0.7967\n",
      "Epoch 394/4000\n",
      "712/712 [==============================] - 1s 732us/step - loss: 0.7663 - accuracy: 0.7467 - val_loss: 0.5600 - val_accuracy: 0.7944\n",
      "Epoch 395/4000\n",
      "712/712 [==============================] - 1s 760us/step - loss: 0.7543 - accuracy: 0.7546 - val_loss: 0.5399 - val_accuracy: 0.8058\n",
      "Epoch 396/4000\n",
      "712/712 [==============================] - 1s 787us/step - loss: 0.7592 - accuracy: 0.7490 - val_loss: 0.5008 - val_accuracy: 0.8127\n",
      "Epoch 397/4000\n",
      "712/712 [==============================] - 1s 776us/step - loss: 0.7637 - accuracy: 0.7505 - val_loss: 0.5062 - val_accuracy: 0.8239\n",
      "Epoch 398/4000\n",
      "712/712 [==============================] - 1s 761us/step - loss: 0.7595 - accuracy: 0.7496 - val_loss: 0.5737 - val_accuracy: 0.7800\n",
      "Epoch 399/4000\n",
      "712/712 [==============================] - 1s 763us/step - loss: 0.7881 - accuracy: 0.7423 - val_loss: 0.5338 - val_accuracy: 0.8097\n",
      "Epoch 400/4000\n",
      "712/712 [==============================] - 1s 769us/step - loss: 0.7557 - accuracy: 0.7536 - val_loss: 0.4961 - val_accuracy: 0.8176\n",
      "Epoch 401/4000\n",
      "712/712 [==============================] - 1s 760us/step - loss: 0.7502 - accuracy: 0.7526 - val_loss: 0.5170 - val_accuracy: 0.8155\n",
      "Epoch 402/4000\n",
      "712/712 [==============================] - 1s 759us/step - loss: 0.7896 - accuracy: 0.7438 - val_loss: 0.6213 - val_accuracy: 0.7630\n",
      "Epoch 403/4000\n",
      "712/712 [==============================] - 1s 846us/step - loss: 0.8056 - accuracy: 0.7374 - val_loss: 0.5305 - val_accuracy: 0.8014\n",
      "Epoch 404/4000\n",
      "712/712 [==============================] - 1s 816us/step - loss: 0.7797 - accuracy: 0.7440 - val_loss: 0.5022 - val_accuracy: 0.8158\n",
      "Epoch 405/4000\n",
      "712/712 [==============================] - 1s 770us/step - loss: 0.7769 - accuracy: 0.7439 - val_loss: 0.5384 - val_accuracy: 0.8069\n",
      "Epoch 406/4000\n",
      "712/712 [==============================] - 1s 769us/step - loss: 0.7771 - accuracy: 0.7445 - val_loss: 0.5238 - val_accuracy: 0.8120\n",
      "Epoch 407/4000\n",
      "712/712 [==============================] - 1s 757us/step - loss: 0.7901 - accuracy: 0.7408 - val_loss: 0.5386 - val_accuracy: 0.7985\n",
      "Epoch 408/4000\n",
      "712/712 [==============================] - 1s 789us/step - loss: 0.7720 - accuracy: 0.7458 - val_loss: 0.5644 - val_accuracy: 0.7879\n",
      "Epoch 409/4000\n",
      "712/712 [==============================] - 1s 740us/step - loss: 0.7736 - accuracy: 0.7419 - val_loss: 0.5741 - val_accuracy: 0.7902\n",
      "Epoch 410/4000\n",
      "712/712 [==============================] - 1s 739us/step - loss: 0.7716 - accuracy: 0.7445 - val_loss: 0.4980 - val_accuracy: 0.8200\n",
      "Epoch 411/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.7655 - accuracy: 0.7444 - val_loss: 0.5252 - val_accuracy: 0.8041\n",
      "Epoch 412/4000\n",
      "712/712 [==============================] - 1s 730us/step - loss: 0.7623 - accuracy: 0.7476 - val_loss: 0.5094 - val_accuracy: 0.8007\n",
      "Epoch 413/4000\n",
      "712/712 [==============================] - 1s 742us/step - loss: 0.7574 - accuracy: 0.7491 - val_loss: 0.5427 - val_accuracy: 0.7990\n",
      "Epoch 414/4000\n",
      "712/712 [==============================] - 1s 737us/step - loss: 0.7420 - accuracy: 0.7563 - val_loss: 0.5655 - val_accuracy: 0.7809\n",
      "Epoch 415/4000\n",
      "712/712 [==============================] - 1s 744us/step - loss: 0.7714 - accuracy: 0.7446 - val_loss: 0.5177 - val_accuracy: 0.7902\n",
      "Epoch 416/4000\n",
      "712/712 [==============================] - 1s 735us/step - loss: 0.7615 - accuracy: 0.7511 - val_loss: 0.5281 - val_accuracy: 0.7849\n",
      "Epoch 417/4000\n",
      "712/712 [==============================] - 1s 741us/step - loss: 0.7700 - accuracy: 0.7472 - val_loss: 0.5098 - val_accuracy: 0.8086\n",
      "Epoch 418/4000\n",
      "712/712 [==============================] - 1s 749us/step - loss: 0.7600 - accuracy: 0.7501 - val_loss: 0.5373 - val_accuracy: 0.7993\n",
      "Epoch 419/4000\n",
      "712/712 [==============================] - 1s 738us/step - loss: 0.7657 - accuracy: 0.7457 - val_loss: 0.5174 - val_accuracy: 0.8016\n",
      "Epoch 420/4000\n",
      "712/712 [==============================] - 1s 736us/step - loss: 0.7514 - accuracy: 0.7505 - val_loss: 0.4787 - val_accuracy: 0.8171\n",
      "Epoch 421/4000\n",
      "712/712 [==============================] - 1s 738us/step - loss: 0.7532 - accuracy: 0.7517 - val_loss: 0.5056 - val_accuracy: 0.8050\n",
      "Epoch 422/4000\n",
      "712/712 [==============================] - 1s 743us/step - loss: 0.7439 - accuracy: 0.7550 - val_loss: 0.4878 - val_accuracy: 0.8044\n",
      "Epoch 423/4000\n",
      "712/712 [==============================] - 1s 751us/step - loss: 0.7445 - accuracy: 0.7527 - val_loss: 0.4861 - val_accuracy: 0.8169\n",
      "Epoch 424/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.7481 - accuracy: 0.7525 - val_loss: 0.4948 - val_accuracy: 0.8071\n",
      "Epoch 425/4000\n",
      "712/712 [==============================] - 1s 737us/step - loss: 0.7371 - accuracy: 0.7550 - val_loss: 0.4611 - val_accuracy: 0.8129\n",
      "Epoch 426/4000\n",
      "712/712 [==============================] - 1s 766us/step - loss: 0.7333 - accuracy: 0.7586 - val_loss: 0.5004 - val_accuracy: 0.8064\n",
      "Epoch 427/4000\n",
      "712/712 [==============================] - 1s 736us/step - loss: 0.7405 - accuracy: 0.7540 - val_loss: 0.4844 - val_accuracy: 0.8046\n",
      "Epoch 428/4000\n",
      "712/712 [==============================] - 1s 744us/step - loss: 0.7262 - accuracy: 0.7595 - val_loss: 0.4564 - val_accuracy: 0.8164\n",
      "Epoch 429/4000\n",
      "712/712 [==============================] - 1s 729us/step - loss: 0.7354 - accuracy: 0.7586 - val_loss: 0.4840 - val_accuracy: 0.8088\n",
      "Epoch 430/4000\n",
      "712/712 [==============================] - 1s 737us/step - loss: 0.7386 - accuracy: 0.7584 - val_loss: 0.5548 - val_accuracy: 0.7960\n",
      "Epoch 431/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.7906 - accuracy: 0.7408 - val_loss: 0.5121 - val_accuracy: 0.8048\n",
      "Epoch 432/4000\n",
      "712/712 [==============================] - 1s 731us/step - loss: 0.7906 - accuracy: 0.7372 - val_loss: 0.5168 - val_accuracy: 0.8039\n",
      "Epoch 433/4000\n",
      "712/712 [==============================] - 1s 798us/step - loss: 0.7853 - accuracy: 0.7432 - val_loss: 0.4964 - val_accuracy: 0.8085\n",
      "Epoch 434/4000\n",
      "712/712 [==============================] - 1s 766us/step - loss: 0.7789 - accuracy: 0.7442 - val_loss: 0.5140 - val_accuracy: 0.8004\n",
      "Epoch 435/4000\n",
      "712/712 [==============================] - 1s 736us/step - loss: 0.8104 - accuracy: 0.7395 - val_loss: 0.5064 - val_accuracy: 0.8028\n",
      "Epoch 436/4000\n",
      "712/712 [==============================] - 1s 738us/step - loss: 0.8163 - accuracy: 0.7342 - val_loss: 0.4984 - val_accuracy: 0.7990\n",
      "Epoch 437/4000\n",
      "712/712 [==============================] - 1s 768us/step - loss: 0.8092 - accuracy: 0.7381 - val_loss: 0.5204 - val_accuracy: 0.7988\n",
      "Epoch 438/4000\n",
      "712/712 [==============================] - 1s 766us/step - loss: 0.8030 - accuracy: 0.7379 - val_loss: 0.5290 - val_accuracy: 0.7927\n",
      "Epoch 439/4000\n",
      "712/712 [==============================] - 1s 756us/step - loss: 0.7961 - accuracy: 0.7406 - val_loss: 0.5060 - val_accuracy: 0.8053\n",
      "Epoch 440/4000\n",
      "712/712 [==============================] - 1s 766us/step - loss: 0.8163 - accuracy: 0.7354 - val_loss: 0.5730 - val_accuracy: 0.7841\n",
      "Epoch 441/4000\n",
      "712/712 [==============================] - 1s 770us/step - loss: 0.8516 - accuracy: 0.7239 - val_loss: 0.5289 - val_accuracy: 0.7951\n",
      "Epoch 442/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 1s 743us/step - loss: 0.8865 - accuracy: 0.7153 - val_loss: 0.5380 - val_accuracy: 0.7992\n",
      "Epoch 443/4000\n",
      "712/712 [==============================] - 1s 759us/step - loss: 0.8889 - accuracy: 0.7180 - val_loss: 0.5554 - val_accuracy: 0.7900\n",
      "Epoch 444/4000\n",
      "712/712 [==============================] - 1s 769us/step - loss: 0.8817 - accuracy: 0.7224 - val_loss: 0.5476 - val_accuracy: 0.7948\n",
      "Epoch 445/4000\n",
      "712/712 [==============================] - 1s 749us/step - loss: 0.8724 - accuracy: 0.7231 - val_loss: 0.5569 - val_accuracy: 0.7867\n",
      "Epoch 446/4000\n",
      "712/712 [==============================] - 1s 763us/step - loss: 0.8730 - accuracy: 0.7214 - val_loss: 0.5681 - val_accuracy: 0.7737\n",
      "Epoch 447/4000\n",
      "712/712 [==============================] - 1s 761us/step - loss: 0.8708 - accuracy: 0.7223 - val_loss: 0.5153 - val_accuracy: 0.7990\n",
      "Epoch 448/4000\n",
      "712/712 [==============================] - 1s 749us/step - loss: 0.8657 - accuracy: 0.7258 - val_loss: 0.5386 - val_accuracy: 0.7967\n",
      "Epoch 449/4000\n",
      "712/712 [==============================] - 1s 748us/step - loss: 0.8534 - accuracy: 0.7259 - val_loss: 0.5048 - val_accuracy: 0.8007\n",
      "Epoch 450/4000\n",
      "712/712 [==============================] - 1s 748us/step - loss: 0.8578 - accuracy: 0.7264 - val_loss: 0.5059 - val_accuracy: 0.8042\n",
      "Epoch 451/4000\n",
      "712/712 [==============================] - 1s 741us/step - loss: 0.8584 - accuracy: 0.7221 - val_loss: 0.4738 - val_accuracy: 0.8167\n",
      "Epoch 452/4000\n",
      "712/712 [==============================] - 1s 763us/step - loss: 0.8512 - accuracy: 0.7301 - val_loss: 0.5619 - val_accuracy: 0.7876\n",
      "Epoch 453/4000\n",
      "712/712 [==============================] - 1s 746us/step - loss: 0.8396 - accuracy: 0.7285 - val_loss: 0.4746 - val_accuracy: 0.8151\n",
      "Epoch 454/4000\n",
      "712/712 [==============================] - 1s 751us/step - loss: 0.8490 - accuracy: 0.7285 - val_loss: 0.4825 - val_accuracy: 0.8153\n",
      "Epoch 455/4000\n",
      "712/712 [==============================] - 1s 749us/step - loss: 0.8341 - accuracy: 0.7327 - val_loss: 0.4895 - val_accuracy: 0.8065\n",
      "Epoch 456/4000\n",
      "712/712 [==============================] - 1s 777us/step - loss: 0.8309 - accuracy: 0.7334 - val_loss: 0.5129 - val_accuracy: 0.7946\n",
      "Epoch 457/4000\n",
      "712/712 [==============================] - 1s 734us/step - loss: 0.8262 - accuracy: 0.7356 - val_loss: 0.4735 - val_accuracy: 0.8155\n",
      "Epoch 458/4000\n",
      "712/712 [==============================] - 1s 732us/step - loss: 0.8319 - accuracy: 0.7356 - val_loss: 0.4562 - val_accuracy: 0.8223\n",
      "Epoch 459/4000\n",
      "712/712 [==============================] - 1s 761us/step - loss: 0.8292 - accuracy: 0.7392 - val_loss: 0.5103 - val_accuracy: 0.7944\n",
      "Epoch 460/4000\n",
      "712/712 [==============================] - 1s 769us/step - loss: 0.8184 - accuracy: 0.7382 - val_loss: 0.4693 - val_accuracy: 0.8162\n",
      "Epoch 461/4000\n",
      "712/712 [==============================] - 1s 739us/step - loss: 0.8119 - accuracy: 0.7425 - val_loss: 0.4792 - val_accuracy: 0.8137\n",
      "Epoch 462/4000\n",
      "712/712 [==============================] - 1s 763us/step - loss: 0.8179 - accuracy: 0.7385 - val_loss: 0.4717 - val_accuracy: 0.8192\n",
      "Epoch 463/4000\n",
      "712/712 [==============================] - 1s 821us/step - loss: 0.8133 - accuracy: 0.7394 - val_loss: 0.4469 - val_accuracy: 0.8178\n",
      "Epoch 464/4000\n",
      "712/712 [==============================] - 1s 773us/step - loss: 0.7984 - accuracy: 0.7468 - val_loss: 0.4883 - val_accuracy: 0.8107\n",
      "Epoch 465/4000\n",
      "712/712 [==============================] - 1s 741us/step - loss: 0.8238 - accuracy: 0.7386 - val_loss: 0.4408 - val_accuracy: 0.8216\n",
      "Epoch 466/4000\n",
      "712/712 [==============================] - 1s 744us/step - loss: 0.8050 - accuracy: 0.7431 - val_loss: 0.4288 - val_accuracy: 0.8336\n",
      "Epoch 467/4000\n",
      "712/712 [==============================] - 1s 742us/step - loss: 0.7981 - accuracy: 0.7466 - val_loss: 0.4403 - val_accuracy: 0.8208\n",
      "Epoch 468/4000\n",
      "712/712 [==============================] - 1s 728us/step - loss: 0.7937 - accuracy: 0.7468 - val_loss: 0.4734 - val_accuracy: 0.8137\n",
      "Epoch 469/4000\n",
      "712/712 [==============================] - 1s 739us/step - loss: 0.7992 - accuracy: 0.7483 - val_loss: 0.4866 - val_accuracy: 0.8137\n",
      "Epoch 470/4000\n",
      "712/712 [==============================] - 1s 739us/step - loss: 0.8014 - accuracy: 0.7421 - val_loss: 0.4726 - val_accuracy: 0.8107\n",
      "Epoch 471/4000\n",
      "712/712 [==============================] - 1s 744us/step - loss: 0.7980 - accuracy: 0.7475 - val_loss: 0.4506 - val_accuracy: 0.8272\n",
      "Epoch 472/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.7939 - accuracy: 0.7464 - val_loss: 0.4674 - val_accuracy: 0.8095\n",
      "Epoch 473/4000\n",
      "712/712 [==============================] - 1s 738us/step - loss: 0.7887 - accuracy: 0.7472 - val_loss: 0.4494 - val_accuracy: 0.8141\n",
      "Epoch 474/4000\n",
      "712/712 [==============================] - 1s 736us/step - loss: 0.7745 - accuracy: 0.7540 - val_loss: 0.4675 - val_accuracy: 0.8107\n",
      "Epoch 475/4000\n",
      "712/712 [==============================] - 1s 740us/step - loss: 0.7776 - accuracy: 0.7545 - val_loss: 0.4356 - val_accuracy: 0.8243\n",
      "Epoch 476/4000\n",
      "712/712 [==============================] - 1s 737us/step - loss: 0.7953 - accuracy: 0.7474 - val_loss: 0.5083 - val_accuracy: 0.7913\n",
      "Epoch 477/4000\n",
      "712/712 [==============================] - 1s 739us/step - loss: 0.7983 - accuracy: 0.7495 - val_loss: 0.4196 - val_accuracy: 0.8281\n",
      "Epoch 478/4000\n",
      "712/712 [==============================] - 1s 741us/step - loss: 0.7886 - accuracy: 0.7519 - val_loss: 0.4740 - val_accuracy: 0.8067\n",
      "Epoch 479/4000\n",
      "712/712 [==============================] - 1s 752us/step - loss: 0.7699 - accuracy: 0.7533 - val_loss: 0.4486 - val_accuracy: 0.8158\n",
      "Epoch 480/4000\n",
      "712/712 [==============================] - 1s 736us/step - loss: 0.7661 - accuracy: 0.7562 - val_loss: 0.4015 - val_accuracy: 0.8369\n",
      "Epoch 481/4000\n",
      "712/712 [==============================] - 1s 736us/step - loss: 0.7641 - accuracy: 0.7574 - val_loss: 0.3996 - val_accuracy: 0.8427\n",
      "Epoch 482/4000\n",
      "712/712 [==============================] - 1s 761us/step - loss: 0.7670 - accuracy: 0.7570 - val_loss: 0.3968 - val_accuracy: 0.8376\n",
      "Epoch 483/4000\n",
      "712/712 [==============================] - 1s 738us/step - loss: 0.7781 - accuracy: 0.7538 - val_loss: 0.4369 - val_accuracy: 0.8281\n",
      "Epoch 484/4000\n",
      "712/712 [==============================] - 1s 735us/step - loss: 0.7605 - accuracy: 0.7552 - val_loss: 0.3984 - val_accuracy: 0.8343\n",
      "Epoch 485/4000\n",
      "712/712 [==============================] - 1s 742us/step - loss: 0.7694 - accuracy: 0.7543 - val_loss: 0.4353 - val_accuracy: 0.8222\n",
      "Epoch 486/4000\n",
      "712/712 [==============================] - 1s 754us/step - loss: 0.7605 - accuracy: 0.7630 - val_loss: 0.4671 - val_accuracy: 0.8141\n",
      "Epoch 487/4000\n",
      "712/712 [==============================] - 1s 733us/step - loss: 0.7690 - accuracy: 0.7543 - val_loss: 0.4493 - val_accuracy: 0.8215\n",
      "Epoch 488/4000\n",
      "712/712 [==============================] - 1s 739us/step - loss: 0.7512 - accuracy: 0.7620 - val_loss: 0.4014 - val_accuracy: 0.8351\n",
      "Epoch 489/4000\n",
      "712/712 [==============================] - 1s 728us/step - loss: 0.7561 - accuracy: 0.7617 - val_loss: 0.4038 - val_accuracy: 0.8364\n",
      "Epoch 490/4000\n",
      "712/712 [==============================] - 1s 742us/step - loss: 0.7530 - accuracy: 0.7632 - val_loss: 0.4190 - val_accuracy: 0.8260\n",
      "Epoch 491/4000\n",
      "712/712 [==============================] - 1s 736us/step - loss: 0.7565 - accuracy: 0.7606 - val_loss: 0.4118 - val_accuracy: 0.8322\n",
      "Epoch 492/4000\n",
      "712/712 [==============================] - 1s 758us/step - loss: 0.7476 - accuracy: 0.7635 - val_loss: 0.4178 - val_accuracy: 0.8339\n",
      "Epoch 493/4000\n",
      "712/712 [==============================] - 1s 810us/step - loss: 0.7611 - accuracy: 0.7617 - val_loss: 0.4231 - val_accuracy: 0.8272\n",
      "Epoch 494/4000\n",
      "712/712 [==============================] - 1s 745us/step - loss: 0.8067 - accuracy: 0.7453 - val_loss: 0.4534 - val_accuracy: 0.8248\n",
      "Epoch 495/4000\n",
      "712/712 [==============================] - 1s 745us/step - loss: 0.7929 - accuracy: 0.7478 - val_loss: 0.4230 - val_accuracy: 0.8269\n",
      "Epoch 00495: early stopping\n",
      "Training Accuracy: 0.858, Testing Accuracy: 0.827\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NN Model for tackler identification\n",
    "\n",
    "# tuning parameters\n",
    "learning_rate = 0.001\n",
    "\n",
    "# model Architecture\n",
    "identityLayers = [keras.layers.Dense(256, activation='relu', input_dim=nFeature),\n",
    "                 keras.layers.Dropout(0.2),\n",
    "                 keras.layers.Dense(128, activation='relu'),\n",
    "                 keras.layers.Dropout(0.2),\n",
    "                 keras.layers.Dense(11, activation='softmax')\n",
    "                ]\n",
    "identityModel = keras.Sequential(identityLayers)\n",
    "\n",
    "# compile model\n",
    "sgd = keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.8) # stochastic gradient descent as optimizer\n",
    "adam = keras.optimizers.Adam(learning_rate=learning_rate) #stochastic gradient descent method based on adaptive \n",
    "                                                          #estimation of 1st order and 2nd order moments\n",
    "identityModel.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=adam, \n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Early Stopping based on validation loss\n",
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=200)\n",
    "mc = keras.callbacks.ModelCheckpoint('best_model.SB', monitor='val_loss', mode='min', verbose=0, save_best_only=True)\n",
    "\n",
    "historyData = identityModel.fit(X_train, Y_identity_train, validation_data=(X_test, Y_identity_test),\n",
    "                               epochs=4000,\n",
    "                               callbacks=[es], \n",
    "                               verbose=1)\n",
    "\n",
    "_, train_acc = identityModel.evaluate(X_train, Y_identity_train, verbose=0)\n",
    "_, test_acc = identityModel.evaluate(X_test, Y_identity_test, verbose=0)\n",
    "print('Training Accuracy: %.3f, Testing Accuracy: %.3f' % (train_acc, test_acc))\n",
    "\n",
    "plt.plot(historyData.history['loss'], label='train')\n",
    "plt.plot(historyData.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.title('Loss over time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d12ae2-f809-4ac3-8845-b9d3ebb24ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
